[
  {
    "objectID": "distributed.multiprocess.html",
    "href": "distributed.multiprocess.html",
    "title": "MultiprocessBackend",
    "section": "",
    "text": "source\n\nMultiprocessBackend\n\n MultiprocessBackend (n_jobs:int)\n\nMultiprocessBackend Parent Class for Distributed Computation.\nParameters: n_jobs: int, number of jobs used in the parallel processing, use -1 for all cores.\nNotes:"
  },
  {
    "objectID": "ces.html",
    "href": "ces.html",
    "title": "CES Model",
    "section": "",
    "text": "source\n\n\n\n ces_target_fn (optimal_param, init_alpha_0, init_alpha_1, init_beta_0,\n                init_beta_1, opt_alpha_0, opt_alpha_1, opt_beta_0,\n                opt_beta_1, y, m, init_states, n_components, seasontype,\n                nmse)\n\n\nforecast_ces(res, 12)"
  },
  {
    "objectID": "distributed.core.html",
    "href": "distributed.core.html",
    "title": "Core",
    "section": "",
    "text": "source\n\nParallelBackend\n\n ParallelBackend ()\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "distributed.utils.html",
    "href": "distributed.utils.html",
    "title": "Distributed utils",
    "section": "",
    "text": "source\n\nforecast\n\n forecast (df, models, freq, h, fallback_model=None, X_df=None,\n           level=None,\n           parallel:Optional[ForwardRef('ParallelBackend')]=None)\n\n\nsource\n\n\ncross_validation\n\n cross_validation (df, models, freq, h, n_windows=1, step_size=1,\n                   test_size=None, input_size=None,\n                   parallel:Optional[ForwardRef('ParallelBackend')]=None)"
  },
  {
    "objectID": "distributed.fugue.html",
    "href": "distributed.fugue.html",
    "title": "FugueBackend",
    "section": "",
    "text": "source"
  },
  {
    "objectID": "distributed.fugue.html#dask-distributed-predictions",
    "href": "distributed.fugue.html#dask-distributed-predictions",
    "title": "FugueBackend",
    "section": "Dask Distributed Predictions",
    "text": "Dask Distributed Predictions\nHere we provide an example for the distribution of the StatsForecast predictions using Fugue to execute the code in a Dask cluster.\nTo do it we instantiate the FugueBackend class with a DaskExecutionEngine.\n\nfrom dask.distributed import Client\nfrom fugue_dask import DaskExecutionEngine\nfrom statsforecast.models import Naive\nfrom statsforecast.utils import generate_series\n\n# Generate Synthetic Panel Data\ndf = generate_series(10).reset_index()\ndf['unique_id'] = df['unique_id'].astype(str)\n\n# Instantiate FugueBackend with DaskExecutionEngine\ndask_client = Client()\nengine = DaskExecutionEngine(dask_client=dask_client)\nfcst = FugueBackend(engine=engine, as_local=True)\n\n\nDistributed Forecast\nFor extremely fast distributed predictions we use FugueBackend.forecast method that operates like the original StatsForecast.forecast method.\nIt receives as input a pandas.DataFrame with columns [unique_id,ds,y] and exogenous, where the ds (datestamp) column should be of a format expected by Pandas. The y column must be numeric, and represents the measurement we wish to forecast. And the unique_id uniquely identifies the series in the panel data.\n\n# Distributed predictions with FugueBackend.\nfcst.forecast(df=df, models=[Naive()], freq='D', h=12)\n# fallback model\nclass FailNaive:\n    def forecast(self):\n        pass\n    def __repr__(self):\n        return 'Naive'\ndask_fcst = fcst.forecast(df=df, models=[FailNaive()], freq='D', fallback_model=Naive(), h=12)\nfcst_stats = StatsForecast(models=[Naive()], freq='D').forecast(df=df, h=12)\ntest_eq(dask_fcst.sort_values(by=['unique_id', 'ds']).reset_index(drop=True), \n        fcst_stats.reset_index())\n\n\n\nDistributed Cross-Validation\nFor extremely fast distributed temporcal cross-validation we use FugueBackend.forecast method that operates like the original StatsForecast.cross_validation method.\n\n# Distributed cross-validation with FugueBackend.\nfcst.cross_validation(df=df, models=[Naive()], freq='D', h=12, n_windows=2)"
  },
  {
    "objectID": "ets.html",
    "href": "ets.html",
    "title": "ETS Model",
    "section": "",
    "text": "source\n\n\n\n ets_target_fn (par, p_y, p_nstate, p_errortype, p_trendtype,\n                p_seasontype, p_damped, p_lower, p_upper, p_opt_crit,\n                p_nmse, p_bounds, p_m, p_optAlpha, p_optBeta, p_optGamma,\n                p_optPhi, p_givenAlpha, p_givenBeta, p_givenGamma,\n                p_givenPhi, alpha, beta, gamma, phi)"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utils",
    "section": "",
    "text": "2. AirPassengers Data \nThe classic Box & Jenkins airline data. Monthly totals of international airline passengers, 1949 to 1960.\nIt has been used as a reference on several forecasting libraries, since it is a series that shows clear trends and seasonalities it offers a nice opportunity to quickly showcase a model’s predictions performance.\n\nfrom statsforecast.utils import AirPassengersDF\n\nAirPassengersDF.head(12)\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n    \n  \n  \n    \n      0\n      1.0\n      1949-01-31\n      112.0\n    \n    \n      1\n      1.0\n      1949-02-28\n      118.0\n    \n    \n      2\n      1.0\n      1949-03-31\n      132.0\n    \n    \n      3\n      1.0\n      1949-04-30\n      129.0\n    \n    \n      4\n      1.0\n      1949-05-31\n      121.0\n    \n    \n      5\n      1.0\n      1949-06-30\n      135.0\n    \n    \n      6\n      1.0\n      1949-07-31\n      148.0\n    \n    \n      7\n      1.0\n      1949-08-31\n      148.0\n    \n    \n      8\n      1.0\n      1949-09-30\n      136.0\n    \n    \n      9\n      1.0\n      1949-10-31\n      119.0\n    \n    \n      10\n      1.0\n      1949-11-30\n      104.0\n    \n    \n      11\n      1.0\n      1949-12-31\n      118.0\n    \n  \n\n\n\n\n\n#We are going to plot the ARIMA predictions, and the prediction intervals.\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nplot_df = AirPassengersDF.set_index('ds')\n\nplot_df[['y']].plot(ax=ax, linewidth=2)\nax.set_title('AirPassengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()"
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": " Models ",
    "section": "",
    "text": "source\n\n\n\n AutoARIMA (d:Optional[int]=None, D:Optional[int]=None, max_p:int=5,\n            max_q:int=5, max_P:int=2, max_Q:int=2, max_order:int=5,\n            max_d:int=2, max_D:int=1, start_p:int=2, start_q:int=2,\n            start_P:int=1, start_Q:int=1, stationary:bool=False,\n            seasonal:bool=True, ic:str='aicc', stepwise:bool=True,\n            nmodels:int=94, trace:bool=False,\n            approximation:Optional[bool]=False, method:Optional[str]=None,\n            truncate:Optional[bool]=None, test:str='kpss',\n            test_kwargs:Optional[str]=None, seasonal_test:str='seas',\n            seasonal_test_kwargs:Optional[Dict]=None,\n            allowdrift:bool=False, allowmean:bool=False,\n            blambda:Optional[float]=None, biasadj:bool=False,\n            parallel:bool=False, num_cores:int=2, season_length:int=1)\n\nAutoARIMA model. Source code.\nAutomatically selects the best ARIMA (AutoRegressive Integrated Moving Average) model using an information criterion. Default is Akaike Information Criterion (AICc).\nParameters: d: int, order of first-differencing. D: int, order of seasonal-differencing. max_p: int, max autorregresives p. max_q: int, max moving averages q. max_P: int, max seasonal autorregresives P. max_Q: int, max seasonal moving averages Q. max_order: int, max p+q+P+Q value if not stepwise selection. max_d: int, max non-seasonal differences. max_D: int, max seasonal differences. start_p: int, starting value of p in stepwise procedure. start_q: int, starting value of q in stepwise procedure. start_P: int, starting value of P in stepwise procedure. start_Q: int, starting value of Q in stepwise procedure. stationary: bool, if True, restricts search to stationary models. seasonal: bool, if False, restricts search to non-seasonal models. ic: str, information criterion to be used in model selection. stepwise: bool, if True, will do stepwise selection (faster). nmodels: int, number of models considered in stepwise search. trace: bool, if True, the searched ARIMA models is reported. approximation: bool, if True, conditional sums-of-squares estimation, final MLE. method: str, fitting method between maximum likelihood or sums-of-squares. truncate: int, observations truncated series used in model selection. test: str (default ‘kpss’), unit root test to use. See ndiffs for details. test_kwargs: str optional (default None), unit root test additional arguments. seasonal_test: str (default ‘seas’), selection method for seasonal differences. seasonal_test_kwargs: dict (optional), seasonal unit root test arguments. allowdrift: bool (default True), If True, drift models terms considered. allowmean: bool (default True), If True, non-zero mean models considered. blambda: float optional (default None), Box-Cox transformation parameter. biasadj: bool (default False), Use adjusted back-transformed mean Box-Cox. parallel: bool, If True and stepwise=False, then parallel search. num_cores: int, amount of parallel processes to be used if parallel=True. season_length: int, number of observations per unit of time. Ex: 24 Hourly data.\nNote: This implementation is a mirror of Hyndman’s forecast::auto.arima.\nReferences: Rob J. Hyndman, Yeasmin Khandakar (2008). “Automatic Time Series Forecasting: The forecast package for R”.\n\nsource\n\n\n\n\n AutoARIMA.fit (y:numpy.ndarray, X:Optional[numpy.ndarray]=None)\n\nFit the AutoARIMA model.\nFit an AutoARIMA to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: AutoARIMA fitted model.\n\nsource\n\n\n\n\n AutoARIMA.predict (h:int, X:numpy.ndarray=None,\n                    level:Optional[Tuple[int]]=None)\n\nPredict with fitted AutoArima.\nParameters: h: int, forecast horizon. X: array-like of shape (h, n_x) optional exogenous (default=None).\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\n\n\n AutoARIMA.predict_in_sample (level:Optional[Tuple[int]]=None)\n\nAccess fitted AutoArima insample predictions.\nParameters: X: array-like of shape (t, n_x) optional exogenous (default=None). level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\n\n\n AutoARIMA.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                     X_future:numpy.ndarray=None,\n                     level:Optional[List[int]]=None, fitted:bool=False)\n\nMemory Efficient AutoARIMA predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. X: array-like of shape (t, n_x) optional insample exogenous (default=None). X_future: array-like of shape (h, n_x) optional exogenous (default=None). level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# AutoARIMA's usage example\n\nfrom statsforecast.models import AutoARIMA\nfrom statsforecast.utils import AirPassengers as ap\n\n\narima = AutoARIMA(season_length=4)\narima = arima.fit(y=ap)\ny_hat_dict = arima.predict(h=4, level=[80])\ny_hat_dict\n\n{'mean': array([497.95290566, 486.78069066, 500.0821497 , 494.10983852]),\n 'lo-80': 0    467.167464\n 1    442.112230\n 2    450.786735\n 3    440.963293\n Name: 80%, dtype: float64,\n 'hi-80': 0    528.738348\n 1    531.449151\n 2    549.377564\n 3    547.256385\n Name: 80%, dtype: float64}\n\n\n\n\n\n\n\nsource\n\n\n\n ETS (season_length:int=1, model:str='ZZZ')\n\nExponential Smoothing model. Source code.\nAutomatically selects the best ETS (Error, Trend, Seasonality) model using an information criterion. Default is Akaike Information Criterion (AICc), while particular models are estimated using maximum likelihood. The state-space equations can be determined based on their \\(M\\) multiplicative, \\(A\\) additive, \\(Z\\) optimized or \\(N\\) ommited components. The model string parameter defines the ETS equations: E in [\\(M, A, Z\\)], T in [\\(N, A, M, Z\\)], and S in [\\(N, A, M, Z\\)].\nFor example when model=‘ANN’ (additive error, no trend, and no seasonality), ETS will explore only a simple exponential smoothing.\nIf the component is selected as ‘Z’, it operates as a placeholder to ask the AutoETS model to figure out the best parameter.\nParameters: model: str, controlling state-space-equations. season_length: int, number of observations per unit of time. Ex: 24 Hourly data.\nNote: This implementation is a mirror of Hyndman’s forecast::ets.\nReferences: Rob J. Hyndman, Yeasmin Khandakar (2008). “Automatic Time Series Forecasting: The forecast package for R”.\nHyndman, Rob, et al (2008). “Forecasting with exponential smoothing: the state space approach”.\n\nsource\n\n\n\n\n ETS.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the Exponential Smoothing model.\nFit an Exponential Smoothing model to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: Exponential Smoothing fitted model.\n\nsource\n\n\n\n\n ETS.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted Exponential Smoothing.\nParameters: h: int, forecast horizon. X: array-like of shape (h, n_x) optional exogenous (default=None).\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\n\n\n ETS.predict_in_sample ()\n\nAccess fitted Exponential Smoothing insample predictions.\nParameters: X: array-like of shape (t, n_x) optional exogenous (default=None). level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\n\n\n ETS.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n               X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient Exponential Smoothing predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. X: array-like of shape (t, n_x) optional insample exogenous (default=None). X_future: array-like of shape (h, n_x) optional exogenous (default=None). level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# ETS' usage example\n\nfrom statsforecast.models import ETS\nfrom statsforecast.utils import AirPassengers as ap\n\n# Multiplicative trend, optimal error and seasonality\nets = ETS(model='ZMZ',  \n          season_length=4)\nets = ets.fit(y=ap)\ny_hat_dict = ets.predict(h=4)\ny_hat_dict\n\n{'mean': array([416.63294737, 419.65915384, 442.66309931, 457.33314074])}\n\n\n\n\n\n\n\nsource\n\n\n\n AutoCES (season_length:int=1, model:str='Z')\n\nComplex Exponential Smoothing model. Source code.\nAutomatically selects the best Complex Exponential Smoothing model using an information criterion. Default is Akaike Information Criterion (AICc), while particular models are estimated using maximum likelihood. The state-space equations can be determined based on their \\(S\\) simple, \\(P\\) parial, \\(Z\\) optimized or \\(N\\) ommited components. The model string parameter defines the kind of CES model: \\(N\\) for simple CES (withous seasonality), \\(S\\) for simple seasonality (lagged CES), \\(P\\) for partial seasonality (without complex part), \\(F\\) for full seasonality (lagged CES with real and complex seasonal parts).\nIf the component is selected as ‘Z’, it operates as a placeholder to ask the AutoCES model to figure out the best parameter.\nParameters: model: str, controlling state-space-equations. season_length: int, number of observations per unit of time. Ex: 24 Hourly data.\nReferences: Svetunkov, Ivan & Kourentzes, Nikolaos. (2015). “Complex Exponential Smoothing”. 10.13140/RG.2.1.3757.2562..\n\nsource\n\n\n\n\n AutoCES.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the Complex Exponential Smoothing model.\nFit the Comples Exponential Smoothing model to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: Complex Exponential Smoothing fitted model.\n\nsource\n\n\n\n\n AutoCES.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted Exponential Smoothing.\nParameters: h: int, forecast horizon. X: array-like of shape (h, n_x) optional exogenous (default=None).\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\n\n\n AutoCES.predict_in_sample ()\n\nAccess fitted Exponential Smoothing insample predictions.\nParameters: X: array-like of shape (t, n_x) optional exogenous (default=None). level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\n\n\n AutoCES.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                   X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient Complex Exponential Smoothing predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. X: array-like of shape (t, n_x) optional insample exogenous (default=None). X_future: array-like of shape (h, n_x) optional exogenous (default=None). fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# ETS' usage example\n\nfrom statsforecast.models import AutoCES\nfrom statsforecast.utils import AirPassengers as ap\n\n# Multiplicative trend, optimal error and seasonality\nces = AutoCES(model='Z',  \n              season_length=4)\nces = ces.fit(y=ap)\ny_hat_dict = ces.predict(h=4)\ny_hat_dict\n\n{'mean': array([424.30716324, 405.69589186, 442.02640533, 443.63488996])}"
  },
  {
    "objectID": "models.html#simplesmooth",
    "href": "models.html#simplesmooth",
    "title": " Models ",
    "section": "SimpleSmooth",
    "text": "SimpleSmooth\n\nsource\n\nSimpleExponentialSmoothing\n\n SimpleExponentialSmoothing (alpha:float)\n\nSimpleExponentialSmoothing model. Source code.\nUses a weighted average of all past observations where the weights decrease exponentially into the past. Suitable for data with no clear trend or seasonality. Assuming there are \\(t\\) observations, the one-step forecast is given by: \\(\\hat{y}_{t+1} = \\alpha y_t + (1-\\alpha) \\hat{y}_{t-1}\\)\nThe rate \\(0 \\leq \\alpha \\leq 1\\) at which the weights decrease is called the smoothing parameter. When \\(\\alpha = 1\\), SES is equal to the naive method.\nParameters: alpha: float, smoothing parameter.\nReferences: Charles C Holt (1957). “Forecasting seasonals and trends by exponentially weighted moving averages”.\n\nsource\n\n\nSimpleExponentialSmoothing.forecast\n\n SimpleExponentialSmoothing.forecast (y:numpy.ndarray, h:int,\n                                      X:numpy.ndarray=None,\n                                      X_future:numpy.ndarray=None,\n                                      fitted:bool=False)\n\nMemory Efficient SimpleExponentialSmoothing predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSimpleExponentialSmoothing.fit\n\n SimpleExponentialSmoothing.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the SimpleExponentialSmoothing model.\nFit an SimpleExponentialSmoothing to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: SimpleExponentialSmoothing fitted model.\n\nsource\n\n\nSimpleExponentialSmoothing.predict\n\n SimpleExponentialSmoothing.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted SimpleExponentialSmoothing.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSimpleExponentialSmoothing.predict_in_sample\n\n SimpleExponentialSmoothing.predict_in_sample ()\n\nAccess fitted SimpleExponentialSmoothing insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# SimpleExponentialSmoothing's usage example\n\nfrom statsforecast.models import SimpleExponentialSmoothing\nfrom statsforecast.utils import AirPassengers as ap\n\n\nses = SimpleExponentialSmoothing(alpha=0.5)\nses = ses.fit(y=ap)\ny_hat_dict = ses.predict(h=4)\ny_hat_dict\n\n{'mean': array([439.256, 439.256, 439.256, 439.256], dtype=float32)}"
  },
  {
    "objectID": "models.html#simplesmoothoptimized",
    "href": "models.html#simplesmoothoptimized",
    "title": " Models ",
    "section": "SimpleSmoothOptimized",
    "text": "SimpleSmoothOptimized\n\nsource\n\nSimpleExponentialSmoothingOptimized\n\n SimpleExponentialSmoothingOptimized ()\n\nSimpleExponentialSmoothing model. Source code.\nUses a weighted average of all past observations where the weights decrease exponentially into the past. Suitable for data with no clear trend or seasonality. Assuming there are \\(t\\) observations, the one-step forecast is given by: \\(\\hat{y}_{t+1} = \\alpha y_t + (1-\\alpha) \\hat{y}_{t-1}\\)\nThe smoothing parameter \\(\\alpha^*\\) is optimized by square error minimization.\nParameters:\nReferences: Charles C Holt (1957). “Forecasting seasonals and trends by exponentially weighted moving averages”.\n\nsource\n\n\nSimpleExponentialSmoothingOptimized.fit\n\n SimpleExponentialSmoothingOptimized.fit (y:numpy.ndarray,\n                                          X:numpy.ndarray=None)\n\nFit the SimpleExponentialSmoothingOptimized model.\nFit an SimpleExponentialSmoothingOptimized to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: SimpleExponentialSmoothingOptimized fitted model.\n\nsource\n\n\nSimpleExponentialSmoothingOptimized.predict\n\n SimpleExponentialSmoothingOptimized.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted SimpleExponentialSmoothingOptimized.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSimpleExponentialSmoothingOptimized.predict_in_sample\n\n SimpleExponentialSmoothingOptimized.predict_in_sample ()\n\nAccess fitted SimpleExponentialSmoothingOptimized insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSimpleExponentialSmoothingOptimized.forecast\n\n SimpleExponentialSmoothingOptimized.forecast (y:numpy.ndarray, h:int,\n                                               X:numpy.ndarray=None, X_fut\n                                               ure:numpy.ndarray=None,\n                                               fitted:bool=False)\n\nMemory Efficient SimpleExponentialSmoothingOptimized predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# SimpleExponentialSmoothingOptimized's usage example\n\nfrom statsforecast.models import SimpleExponentialSmoothingOptimized\nfrom statsforecast.utils import AirPassengers as ap\n\n\nseso = SimpleExponentialSmoothingOptimized()\nseso = seso.fit(y=ap)\ny_hat_dict = seso.predict(h=4)\ny_hat_dict\n\n{'mean': array([431.58716, 431.58716, 431.58716, 431.58716], dtype=float32)}"
  },
  {
    "objectID": "models.html#seasonalsmooth",
    "href": "models.html#seasonalsmooth",
    "title": " Models ",
    "section": "SeasonalSmooth",
    "text": "SeasonalSmooth\n\nsource\n\nSeasonalExponentialSmoothing\n\n SeasonalExponentialSmoothing (season_length:int, alpha:float)\n\nSeasonalExponentialSmoothing model. Source code.\nUses a weighted average of all past observations where the weights decrease exponentially into the past. Suitable for data with no clear trend or seasonality. Assuming there are \\(t\\) observations and season \\(s\\), the one-step forecast is given by: \\(\\hat{y}_{t+1,s} = \\alpha y_t + (1-\\alpha) \\hat{y}_{t-1,s}\\)\nNote: This method is an extremely simplified of Holt-Winter’s method where the trend and level are set to zero. And a single seasonal smoothing parameter \\(\\alpha\\) is shared across seasons.\nParameters: alpha: float, smoothing parameter. season_length: int, number of observations per unit of time. Ex: 24 Hourly data.\nReferences: Charles. C. Holt (1957). “Forecasting seasonals and trends by exponentially weighted moving averages”, ONR Research Memorandum, Carnegie Institute of Technology 52..\nPeter R. Winters (1960). “Forecasting sales by exponentially weighted moving averages”. Management Science.\n\nsource\n\n\nSeasonalExponentialSmoothing.fit\n\n SeasonalExponentialSmoothing.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the SeasonalExponentialSmoothing model.\nFit an SeasonalExponentialSmoothing to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: SeasonalExponentialSmoothing fitted model.\n\nsource\n\n\nSeasonalExponentialSmoothing.predict\n\n SeasonalExponentialSmoothing.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted SeasonalExponentialSmoothing.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSeasonalExponentialSmoothing.predict_in_sample\n\n SeasonalExponentialSmoothing.predict_in_sample ()\n\nAccess fitted SeasonalExponentialSmoothing insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSeasonalExponentialSmoothing.forecast\n\n SeasonalExponentialSmoothing.forecast (y:numpy.ndarray, h:int,\n                                        X:numpy.ndarray=None,\n                                        X_future:numpy.ndarray=None,\n                                        fitted:bool=False)\n\nMemory Efficient SeasonalExponentialSmoothing predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# SeasonalExponentialSmoothing's usage example\n\nfrom statsforecast.models import SeasonalExponentialSmoothing\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = SeasonalExponentialSmoothing(alpha=0.5, season_length=12)\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([376.28955, 354.71094, 396.02002, 412.06738], dtype=float32)}"
  },
  {
    "objectID": "models.html#seasonalsmoothoptimized",
    "href": "models.html#seasonalsmoothoptimized",
    "title": " Models ",
    "section": "SeasonalSmoothOptimized",
    "text": "SeasonalSmoothOptimized\n\nsource\n\nSeasonalExponentialSmoothingOptimized\n\n SeasonalExponentialSmoothingOptimized (season_length:int)\n\nSeasonalExponentialSmoothingOptimized model. Source code.\nUses a weighted average of all past observations where the weights decrease exponentially into the past. Suitable for data with no clear trend or seasonality. Assuming there are \\(t\\) observations and season \\(s\\), the one-step forecast is given by: \\(\\hat{y}_{t+1,s} = \\alpha y_t + (1-\\alpha) \\hat{y}_{t-1,s}\\)\nThe smoothing parameter \\(\\alpha^*\\) is optimized by square error minimization.\nNote: This method is an extremely simplified of Holt-Winter’s method where the trend and level are set to zero. And a single seasonal smoothing parameter \\(\\alpha\\) is shared across seasons.\nParameters: season_length: int, number of observations per unit of time. Ex: 24 Hourly data.\nReferences: Charles. C. Holt (1957). “Forecasting seasonals and trends by exponentially weighted moving averages”, ONR Research Memorandum, Carnegie Institute of Technology 52..\nPeter R. Winters (1960). “Forecasting sales by exponentially weighted moving averages”. Management Science.\n\nsource\n\n\nSeasonalExponentialSmoothingOptimized.forecast\n\n SeasonalExponentialSmoothingOptimized.forecast (y:numpy.ndarray, h:int,\n                                                 X:numpy.ndarray=None, X_f\n                                                 uture:numpy.ndarray=None,\n                                                 fitted:bool=False)\n\nMemory Efficient SeasonalExponentialSmoothingOptimized predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSeasonalExponentialSmoothingOptimized.fit\n\n SeasonalExponentialSmoothingOptimized.fit (y:numpy.ndarray,\n                                            X:numpy.ndarray=None)\n\nFit the SeasonalExponentialSmoothingOptimized model.\nFit an SeasonalExponentialSmoothingOptimized to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: SeasonalExponentialSmoothingOptimized fitted model.\n\nsource\n\n\nSeasonalExponentialSmoothingOptimized.predict\n\n SeasonalExponentialSmoothingOptimized.predict (h:int,\n                                                X:numpy.ndarray=None)\n\nPredict with fitted SeasonalExponentialSmoothingOptimized.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSeasonalExponentialSmoothingOptimized.predict_in_sample\n\n SeasonalExponentialSmoothingOptimized.predict_in_sample ()\n\nAccess fitted SeasonalExponentialSmoothingOptimized insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# SeasonalExponentialSmoothingOptimized's usage example\n\nfrom statsforecast.models import SeasonalExponentialSmoothingOptimized\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = SeasonalExponentialSmoothingOptimized(season_length=12)\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([416.42798, 390.50757, 418.8656 , 460.3452 ], dtype=float32)}"
  },
  {
    "objectID": "models.html#holts-method",
    "href": "models.html#holts-method",
    "title": " Models ",
    "section": "Holt’s method",
    "text": "Holt’s method\n\nsource\n\nHolt\n\n Holt (season_length:int=1, error_type:str='A')\n\nHolt’s method.\nAlso known as double exponential smoothing, Holt’s method is an extension of exponential smoothing for series with a trend. This implementation returns the corresponding ETS model with additive (A) or multiplicative (M) errors (so either ‘AAN’ or ‘MAN’).\nParameters: season_length: int, number of observations per unit of time. Ex: 12 Monthly data. \nerror_type: The type of error of the ETS model. Can be additive (A) or multiplicative (M). \nReferences: - Rob J. Hyndman and George Athanasopoulos (2018). “Forecasting principles and practice, Methods with trend”.\n\nsource\n\n\nHolt.forecast\n\n Holt.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient Exponential Smoothing predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. X: array-like of shape (t, n_x) optional insample exogenous (default=None). X_future: array-like of shape (h, n_x) optional exogenous (default=None). level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nHolt.fit\n\n Holt.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the Exponential Smoothing model.\nFit an Exponential Smoothing model to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: Exponential Smoothing fitted model.\n\nsource\n\n\nHolt.predict\n\n Holt.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted Exponential Smoothing.\nParameters: h: int, forecast horizon. X: array-like of shape (h, n_x) optional exogenous (default=None).\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nHolt.predict_in_sample\n\n Holt.predict_in_sample ()\n\nAccess fitted Exponential Smoothing insample predictions.\nParameters: X: array-like of shape (t, n_x) optional exogenous (default=None). level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# Holt's usage example\n\n#from statsforecast.models import Holt\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = Holt(season_length=12, error_type='A')\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([434.27026573, 436.5445037 , 438.81874167, 441.09297963])}"
  },
  {
    "objectID": "models.html#holt-winters-method",
    "href": "models.html#holt-winters-method",
    "title": " Models ",
    "section": "Holt-Winters’ method",
    "text": "Holt-Winters’ method\n\nsource\n\nHoltWinters\n\n HoltWinters (season_length:int=1, error_type:str='A')\n\nHolt-Winters’ method.\nAlso known as triple exponential smoothing, Holt-Winters’ method is an extension of exponential smoothing for series that contain both trend and seasonality. This implementation returns the corresponding ETS model with additive (A) or multiplicative (M) errors (so either ‘AAA’ or ‘MAM’).\nParameters: season_length: int, number of observations per unit of time. Ex: 12 Monthly data. \nerror_type: The type of error of the ETS model. Can be additive (A) or multiplicative (M). \nReferences: - Rob J. Hyndman and George Athanasopoulos (2018). “Forecasting principles and practice, Methods with seasonality”.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nseason_length\nint\n1\nseason length\n\n\nerror_type\nstr\nA\nerror type\n\n\n\n\nsource\n\n\nHoltWinters.forecast\n\n HoltWinters.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                       X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient Exponential Smoothing predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. X: array-like of shape (t, n_x) optional insample exogenous (default=None). X_future: array-like of shape (h, n_x) optional exogenous (default=None). level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nHoltWinters.fit\n\n HoltWinters.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the Exponential Smoothing model.\nFit an Exponential Smoothing model to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: Exponential Smoothing fitted model.\n\nsource\n\n\nHoltWinters.predict\n\n HoltWinters.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted Exponential Smoothing.\nParameters: h: int, forecast horizon. X: array-like of shape (h, n_x) optional exogenous (default=None).\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nHoltWinters.predict_in_sample\n\n HoltWinters.predict_in_sample ()\n\nAccess fitted Exponential Smoothing insample predictions.\nParameters: X: array-like of shape (t, n_x) optional exogenous (default=None). level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# Holt-Winters' usage example\n\n#from statsforecast.models import HoltWinters\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = HoltWinters(season_length=12, error_type='A')\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([440.4192839 , 414.82970205, 449.80384898, 493.35229084])}"
  },
  {
    "objectID": "models.html#historicaverage",
    "href": "models.html#historicaverage",
    "title": " Models ",
    "section": "HistoricAverage",
    "text": "HistoricAverage\n\nsource\n\nHistoricAverage\n\n HistoricAverage ()\n\nHistoricAverage model. Source code.\nAlso known as mean method. Uses a simple average of all past observations. Assuming there are \\(t\\) observations, the one-step forecast is given by: \\[ \\hat{y}_{t+1} = \\frac{1}{t} \\sum_{j=1}^t y_j \\]\nParameters:\nReferences: Rob J. Hyndman and George Athanasopoulos (2018). “Forecasting principles and practice, Simple Methods”.\n\nsource\n\n\nHistoricAverage.forecast\n\n HistoricAverage.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                           X_future:numpy.ndarray=None, fitted:bool=False,\n                           level:Optional[Tuple[int]]=None)\n\nMemory Efficient HistoricAverage predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nHistoricAverage.fit\n\n HistoricAverage.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the HistoricAverage model.\nFit an HistoricAverage to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: HistoricAverage fitted model.\n\nsource\n\n\nHistoricAverage.predict\n\n HistoricAverage.predict (h:int, X:numpy.ndarray=None,\n                          level:Optional[Tuple[int]]=None)\n\nPredict with fitted HistoricAverage.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nHistoricAverage.predict_in_sample\n\n HistoricAverage.predict_in_sample ()\n\nAccess fitted HistoricAverage insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# HistoricAverage's usage example\n\nfrom statsforecast.models import HistoricAverage\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = HistoricAverage()\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([280.2986, 280.2986, 280.2986, 280.2986], dtype=float32)}"
  },
  {
    "objectID": "models.html#naive",
    "href": "models.html#naive",
    "title": " Models ",
    "section": "Naive",
    "text": "Naive\n\nsource\n\nNaive\n\n Naive ()\n\nNaive model. Source code.\nAlso known as mean method. Uses a simple average of all past observations. Assuming there are \\(t\\) observations, the one-step forecast is given by: \\[ \\hat{y}_{t+1} = y_t \\]\nParameters:\nReferences: Rob J. Hyndman and George Athanasopoulos (2018). “forecasting principles and practice, Simple Methods”.\n\nsource\n\n\nNaive.forecast\n\n Naive.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                 X_future:numpy.ndarray=None, fitted:bool=False,\n                 level:Optional[Tuple[int]]=None)\n\nMemory Efficient Naive predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nNaive.fit\n\n Naive.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the Naive model.\nFit an Naive to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: Naive fitted model.\n\nsource\n\n\nNaive.predict\n\n Naive.predict (h:int, X:numpy.ndarray=None,\n                level:Optional[Tuple[int]]=None)\n\nPredict with fitted Naive.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nforecasting horizon\n\n\nX\nndarray\nNone\nexogenous regressors\n\n\nlevel\nOptional\nNone\nconfidence level\n\n\n\n\nsource\n\n\nNaive.predict_in_sample\n\n Naive.predict_in_sample ()\n\nAccess fitted Naive insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# Naive's usage example\n\nfrom statsforecast.models import Naive\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = Naive()\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([432., 432., 432., 432.], dtype=float32)}"
  },
  {
    "objectID": "models.html#randomwalkwithdrift",
    "href": "models.html#randomwalkwithdrift",
    "title": " Models ",
    "section": "RandomWalkWithDrift",
    "text": "RandomWalkWithDrift\n\nsource\n\nRandomWalkWithDrift\n\n RandomWalkWithDrift ()\n\nRandomWalkWithDrift model. Source code.\nA variation of the naive method allows the forecasts to change over time. The amout of change, called drift, is the average change seen in the historical data.\n\\[ \\hat{y}_{t+1} = y_t+\\frac{1}{t-1}\\sum_{j=1}^t (y_j-y_{j-1}) = y_t+ \\frac{y_t-y_1}{t-1} \\]\nFrom the previous equation, we can see that this is equivalent to extrapolating a line between the first and the last observation.\nParameters:\nReferences: Rob J. Hyndman and George Athanasopoulos (2018). “forecasting principles and practice, Simple Methods”.\n\nsource\n\n\nRandomWalkWithDrift.forecast\n\n RandomWalkWithDrift.forecast (y:numpy.ndarray, h:int,\n                               X:numpy.ndarray=None,\n                               X_future:numpy.ndarray=None,\n                               fitted:bool=False,\n                               level:Optional[Tuple[int]]=None)\n\nMemory Efficient RandomWalkWithDrift predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nRandomWalkWithDrift.fit\n\n RandomWalkWithDrift.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the RandomWalkWithDrift model.\nFit an RandomWalkWithDrift to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: RandomWalkWithDrift fitted model.\n\nsource\n\n\nRandomWalkWithDrift.predict\n\n RandomWalkWithDrift.predict (h:int, X:numpy.ndarray=None,\n                              level:Optional[Tuple[int]]=None)\n\nPredict with fitted RandomWalkWithDrift.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nRandomWalkWithDrift.predict_in_sample\n\n RandomWalkWithDrift.predict_in_sample ()\n\nAccess fitted RandomWalkWithDrift insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# RandomWalkWithDrift's usage example\n\nfrom statsforecast.models import RandomWalkWithDrift\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = RandomWalkWithDrift()\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([434.23776, 436.47552, 438.7133 , 440.95105], dtype=float32)}"
  },
  {
    "objectID": "models.html#seasonalnaive",
    "href": "models.html#seasonalnaive",
    "title": " Models ",
    "section": "SeasonalNaive",
    "text": "SeasonalNaive\n\nsource\n\nSeasonalNaive\n\n SeasonalNaive (season_length:int)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nSeasonalNaive.forecast\n\n SeasonalNaive.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                         X_future:numpy.ndarray=None, fitted:bool=False,\n                         level:Optional[Tuple[int]]=None)\n\nMemory Efficient SeasonalNaive predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSeasonalNaive.fit\n\n SeasonalNaive.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the SeasonalNaive model.\nFit an SeasonalNaive to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: SeasonalNaive fitted model.\n\nsource\n\n\nSeasonalNaive.predict\n\n SeasonalNaive.predict (h:int, X:numpy.ndarray=None,\n                        level:Optional[Tuple[int]]=None)\n\nPredict with fitted Naive.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSeasonalNaive.predict_in_sample\n\n SeasonalNaive.predict_in_sample ()\n\nAccess fitted SeasonalNaive insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# SeasonalNaive's usage example\n\nfrom statsforecast.models import SeasonalNaive\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = SeasonalNaive(season_length=12)\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([417., 391., 419., 461.], dtype=float32)}"
  },
  {
    "objectID": "models.html#windowaverage",
    "href": "models.html#windowaverage",
    "title": " Models ",
    "section": "WindowAverage",
    "text": "WindowAverage\n\nsource\n\nWindowAverage\n\n WindowAverage (window_size:int)\n\nWindowAverage model. Source code.\nUses the average of the last \\(k\\) observations, with \\(k\\) the length of the window. Wider windows will capture global trends, while narrow windows will reveal local trends. The length of the window selected should take into account the importance of past observations and how fast the series changes.\nParameters: window_size: int, size of truncated series on which average is estimated.\nReferences: Rob J. Hyndman and George Athanasopoulos (2018). “forecasting principles and practice, Simple Methods”.\n\nsource\n\n\nWindowAverage.forecast\n\n WindowAverage.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                         X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient WindowAverage predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nWindowAverage.fit\n\n WindowAverage.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the WindowAverage model.\nFit an WindowAverage to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: WindowAverage fitted model.\n\nsource\n\n\nWindowAverage.predict\n\n WindowAverage.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted WindowAverage.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nWindowAverage.predict_in_sample\n\n WindowAverage.predict_in_sample ()\n\nAccess fitted WindowAverage insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# WindowAverage's usage example\n\nfrom statsforecast.models import WindowAverage\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = WindowAverage(window_size=12*4)\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([413.47916, 413.47916, 413.47916, 413.47916], dtype=float32)}"
  },
  {
    "objectID": "models.html#seasonalwindowaverage",
    "href": "models.html#seasonalwindowaverage",
    "title": " Models ",
    "section": "SeasonalWindowAverage",
    "text": "SeasonalWindowAverage\n\nsource\n\nSeasonalWindowAverage\n\n SeasonalWindowAverage (season_length:int, window_size:int)\n\nSeasonalWindowAverage model. Source code.\nAn average of the last \\(k\\) observations of the same period, with \\(k\\) the length of the window.\nParameters: window_size: int, size of truncated series on which average is estimated. seasonal_length: int, number of observations per cycle.\nReferences: Rob J. Hyndman and George Athanasopoulos (2018). “forecasting principles and practice, Simple Methods”.\n\nsource\n\n\nSeasonalWindowAverage.forecast\n\n SeasonalWindowAverage.forecast (y:numpy.ndarray, h:int,\n                                 X:numpy.ndarray=None,\n                                 X_future:numpy.ndarray=None,\n                                 fitted:bool=False)\n\nMemory Efficient SeasonalWindowAverage predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSeasonalWindowAverage.fit\n\n SeasonalWindowAverage.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the SeasonalWindowAverage model.\nFit an SeasonalWindowAverage to a time series (numpy array) y and optionally exogenous variables (numpy array) X.\nParameters: y: numpy array of shape (t, ), clean time series. X: array-like of shape (t, n_x) optional exogenous (default=None).\nReturns: self: SeasonalWindowAverage fitted model.\n\nsource\n\n\nSeasonalWindowAverage.predict\n\n SeasonalWindowAverage.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted SeasonalWindowAverage.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nSeasonalWindowAverage.predict_in_sample\n\n SeasonalWindowAverage.predict_in_sample ()\n\nAccess fitted SeasonalWindowAverage insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# SeasonalWindowAverage's usage example\n\nfrom statsforecast.models import SeasonalWindowAverage\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = SeasonalWindowAverage(season_length=12, window_size=4)\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([358.  , 338.  , 385.75, 388.25], dtype=float32)}"
  },
  {
    "objectID": "models.html#adida",
    "href": "models.html#adida",
    "title": " Models ",
    "section": "ADIDA",
    "text": "ADIDA\n\nsource\n\nADIDA\n\n ADIDA ()\n\nADIDA model. Source code.\nAggregate-Dissagregate Intermittent Demand Approach: Uses temporal aggregation to reduce the number of zero observations. Once the data has been agregated, it uses the optimized SES to generate the forecasts at the new level. It then breaks down the forecast to the original level using equal weights.\nADIDA specializes on sparse or intermittent series are series with very few non-zero observations. They are notoriously hard to forecast, and so, different methods have been developed especifically for them.\nParameters:\nReferences: Nikolopoulos, K., Syntetos, A. A., Boylan, J. E., Petropoulos, F., & Assimakopoulos, V. (2011). An aggregate–disaggregate intermittent demand approach (ADIDA) to forecasting: an empirical proposition and analysis. Journal of the Operational Research Society, 62(3), 544-554..\n\nsource\n\n\nADIDA.forecast\n\n ADIDA.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                 X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient ADIDA predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nADIDA.fit\n\n ADIDA.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the ADIDA model.\nFit an ADIDA to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: ADIDA fitted model.\n\nsource\n\n\nADIDA.predict\n\n ADIDA.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted ADIDA.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nADIDA.predict_in_sample\n\n ADIDA.predict_in_sample ()\n\nAccess fitted ADIDA insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# ADIDA's usage example\n\nfrom statsforecast.models import ADIDA\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = ADIDA()\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([461.7666, 461.7666, 461.7666, 461.7666], dtype=float32)}"
  },
  {
    "objectID": "models.html#crostonclassic",
    "href": "models.html#crostonclassic",
    "title": " Models ",
    "section": "CrostonClassic",
    "text": "CrostonClassic\n\nsource\n\nCrostonClassic\n\n CrostonClassic ()\n\nCrostonClassic model. Source code.\nA method to forecast time series that exhibit intermittent demand. It decomposes the original time series into a non-zero demand size \\(z_t\\) and inter-demand intervals \\(p_t\\). Then the forecast is given by: \\[ \\hat{y}_t = \\frac{\\hat{z}_t}{\\hat{p}_t} \\]\nwhere \\(\\hat{z}_t\\) and \\(\\hat{p}_t\\) are forecasted using SES. The smoothing parameter of both components is set equal to 0.1\nParameters:\nReferences: Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303.\n\nsource\n\n\nCrostonClassic.forecast\n\n CrostonClassic.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                          X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient CrostonClassic predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nCrostonClassic.fit\n\n CrostonClassic.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the CrostonClassic model.\nFit an CrostonClassic to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: CrostonClassic fitted model.\n\nsource\n\n\nCrostonClassic.predict\n\n CrostonClassic.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted CrostonClassic.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nCrostonClassic.predict_in_sample\n\n CrostonClassic.predict_in_sample (level)\n\nAccess fitted CrostonClassic insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# CrostonClassic's usage example\n\nfrom statsforecast.models import CrostonClassic\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = CrostonClassic()\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([460.30276, 460.30276, 460.30276, 460.30276], dtype=float32)}"
  },
  {
    "objectID": "models.html#crostonoptimized",
    "href": "models.html#crostonoptimized",
    "title": " Models ",
    "section": "CrostonOptimized",
    "text": "CrostonOptimized\n\nsource\n\nCrostonOptimized\n\n CrostonOptimized ()\n\nCrostonOptimized model. Source code.\nA method to forecast time series that exhibit intermittent demand. It decomposes the original time series into a non-zero demand size \\(z_t\\) and inter-demand intervals \\(p_t\\). Then the forecast is given by: \\[ \\hat{y}_t = \\frac{\\hat{z}_t}{\\hat{p}_t} \\]\nA variation of the classic Croston’s method where the smooting paramater is optimally selected from the range \\([0.1,0.3]\\). Both the non-zero demand \\(z_t\\) and the inter-demand intervals \\(p_t\\) are smoothed separately, so their smoothing parameters can be different.\nParameters:\nReferences: Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303..\n\nsource\n\n\nCrostonOptimized.forecast\n\n CrostonOptimized.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                            X_future:numpy.ndarray=None,\n                            fitted:bool=False)\n\nMemory Efficient CrostonOptimized predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nCrostonOptimized.fit\n\n CrostonOptimized.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the CrostonOptimized model.\nFit an CrostonOptimized to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: CrostonOptimized fitted model.\n\nsource\n\n\nCrostonOptimized.predict\n\n CrostonOptimized.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted CrostonOptimized.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nCrostonOptimized.predict_in_sample\n\n CrostonOptimized.predict_in_sample ()\n\nAccess fitted CrostonOptimized insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nModel description\n\n# CrostonOptimized's usage example\n\nfrom statsforecast.models import CrostonOptimized\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = CrostonOptimized()\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([461.7666, 461.7666, 461.7666, 461.7666], dtype=float32)}"
  },
  {
    "objectID": "models.html#crostonsba",
    "href": "models.html#crostonsba",
    "title": " Models ",
    "section": "CrostonSBA",
    "text": "CrostonSBA\n\nsource\n\nCrostonSBA\n\n CrostonSBA ()\n\nCrostonSBA model. Source code.\nA method to forecast time series that exhibit intermittent demand. It decomposes the original time series into a non-zero demand size \\(z_t\\) and inter-demand intervals \\(p_t\\). Then the forecast is given by: \\[ \\hat{y}_t = \\frac{\\hat{z}_t}{\\hat{p}_t} \\]\nA variation of the classic Croston’s method that uses a debiasing factor, so that the forecast is given by: \\[ \\hat{y}_t = 0.95  \\frac{\\hat{z}_t}{\\hat{p}_t} \\]\nParameters:\nReferences: Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303..\n\nsource\n\n\nCrostonSBA.forecast\n\n CrostonSBA.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                      X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient CrostonSBA predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nCrostonSBA.fit\n\n CrostonSBA.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the CrostonSBA model.\nFit an CrostonSBA to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: CrostonSBA fitted model.\n\nsource\n\n\nCrostonSBA.predict\n\n CrostonSBA.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted CrostonSBA.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nCrostonSBA.predict_in_sample\n\n CrostonSBA.predict_in_sample ()\n\nAccess fitted CrostonSBA insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# CrostonSBA's usage example\n\nfrom statsforecast.models import CrostonSBA\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = CrostonSBA()\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([437.28763, 437.28763, 437.28763, 437.28763], dtype=float32)}"
  },
  {
    "objectID": "models.html#imapa",
    "href": "models.html#imapa",
    "title": " Models ",
    "section": "IMAPA",
    "text": "IMAPA\n\nsource\n\nIMAPA\n\n IMAPA ()\n\nIMAPA model. Source code.\nIntermittent Multiple Aggregation Prediction Algorithm: Similar to ADIDA, but instead of using a single aggregation level, it considers multiple in order to capture different dynamics of the data. Uses the optimized SES to generate the forecasts at the new levels and then combines them using a simple average.\nParameters:\nReferences: - Syntetos, A. A., & Boylan, J. E. (2021). Intermittent demand forecasting: Context, methods and applications. John Wiley & Sons..\n\nsource\n\n\nIMAPA.forecast\n\n IMAPA.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n                 X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient IMAPA predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nIMAPA.fit\n\n IMAPA.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the IMAPA model.\nFit an IMAPA to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: IMAPA fitted model.\n\nsource\n\n\nIMAPA.predict\n\n IMAPA.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted IMAPA.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nIMAPA.predict_in_sample\n\n IMAPA.predict_in_sample ()\n\nAccess fitted IMAPA insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# IMAPA's usage example\n\nfrom statsforecast.models import IMAPA\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = IMAPA()\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([461.7666, 461.7666, 461.7666, 461.7666], dtype=float32)}"
  },
  {
    "objectID": "models.html#tsb",
    "href": "models.html#tsb",
    "title": " Models ",
    "section": "TSB",
    "text": "TSB\n\nsource\n\nTSB\n\n TSB (alpha_d:float, alpha_p:float)\n\nTSB model. Source code.\nTeunter-Syntetos-Babai: A modification of Croston’s method that replaces the inter-demand intervals with the demand probability \\(d_t\\), which is defined as follows.\n\\[\nd_t = \\begin{cases}\n    1  & \\text{if demand occurs at time t} \\\\\n    0  & \\text{otherwise.}\n\\end{cases}\n\\]\nHence, the forecast is given by\n\\[\\hat{y}_t= \\hat{d}_t\\hat{z_t}\\]\nBoth \\(d_t\\) and \\(z_t\\) are forecasted using SES. The smooting paramaters of each may differ, like in the optimized Croston’s method.\nParameters: alpha_d: float, smoothing parameter for demand alpha_p: float, smoothing parameter for probability\nReferences: - Teunter, R. H., Syntetos, A. A., & Babai, M. Z. (2011). Intermittent demand: Linking forecasting to inventory obsolescence. European Journal of Operational Research, 214(3), 606-615.\n\nsource\n\n\nTSB.forecast\n\n TSB.forecast (y:numpy.ndarray, h:int, X:numpy.ndarray=None,\n               X_future:numpy.ndarray=None, fitted:bool=False)\n\nMemory Efficient TSB predictions.\nThis method avoids memory burden due from object storage. It is analogous to fit_predict without storing information. It assumes you know the forecast horizon in advance.\nParameters: y: numpy array of shape (n,), clean time series. h: int, forecast horizon. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nTSB.fit\n\n TSB.fit (y:numpy.ndarray, X:numpy.ndarray=None)\n\nFit the TSB model.\nFit an TSB to a time series (numpy array) y.\nParameters: y: numpy array of shape (t, ), clean time series.\nReturns: self: TSB fitted model.\n\nsource\n\n\nTSB.predict\n\n TSB.predict (h:int, X:numpy.ndarray=None)\n\nPredict with fitted TSB.\nParameters: h: int, forecast horizon.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\nsource\n\n\nTSB.predict_in_sample\n\n TSB.predict_in_sample ()\n\nAccess fitted TSB insample predictions.\nParameters: level: float list 0-100, confidence levels for prediction intervals.\nReturns: forecasts: dictionary, with entries ‘mean’ for point predictions and ’level_*’ for probabilistic predictions.\n\n# TSB's usage example\n\nfrom statsforecast.models import TSB\nfrom statsforecast.utils import AirPassengers as ap\n\n\nmodel = TSB(alpha_d=0.5, alpha_p=0.5)\nmodel = model.fit(y=ap)\ny_hat_dict = model.predict(h=4)\ny_hat_dict\n\n{'mean': array([439.256, 439.256, 439.256, 439.256], dtype=float32)}"
  },
  {
    "objectID": "adapters.prophet.html",
    "href": "adapters.prophet.html",
    "title": "Replace FB-Prophet",
    "section": "",
    "text": "source\n\n\n\n AutoARIMAProphet (growth='linear', changepoints=None, n_changepoints=25,\n                   changepoint_range=0.8, yearly_seasonality='auto',\n                   weekly_seasonality='auto', daily_seasonality='auto',\n                   holidays=None, seasonality_mode='additive',\n                   seasonality_prior_scale=10.0,\n                   holidays_prior_scale=10.0,\n                   changepoint_prior_scale=0.05, mcmc_samples=0,\n                   interval_width=0.8, uncertainty_samples=1000,\n                   stan_backend=None, d=None, D=None, max_p=5, max_q=5,\n                   max_P=2, max_Q=2, max_order=5, max_d=2, max_D=1,\n                   start_p=2, start_q=2, start_P=1, start_Q=1,\n                   stationary=False, seasonal=True, ic='aicc',\n                   stepwise=True, nmodels=94, trace=False,\n                   approximation=False, method=None, truncate=None,\n                   test='kpss', test_kwargs=None, seasonal_test='seas',\n                   seasonal_test_kwargs=None, allowdrift=False,\n                   allowmean=False, blambda=None, biasadj=False,\n                   parallel=False, num_cores=2, period=1)\n\nAutoARIMAProphet adapter.\nReturns best ARIMA model using external variables created by the Prophet interface. This class receives as parameters the same as prophet.Prophet and uses a models.AutoARIMA backend.\nIf your forecasting pipeline uses Prophet the AutoARIMAProphet adapter helps to easily substitute Prophet with an AutoARIMA.\nParameters: growth: String ‘linear’, ‘logistic’ or ‘flat’ to specify a linear, logistic or flat trend. changepoints: List of dates of potential changepoints. Otherwise selected automatically. n_changepoints: Number of potential changepoints to include. changepoint_range: Proportion of history in which trend changepoints will be estimated. yearly_seasonality: Fit yearly seasonality. Can be ‘auto’, True, False, or a number of Fourier terms to generate. weekly_seasonality: Fit weekly seasonality. Can be ‘auto’, True, False, or a number of Fourier terms to generate. daily_seasonality: Fit daily seasonality. Can be ‘auto’, True, False, or a number of Fourier terms to generate. holidays: pandas.DataFrame with columns holiday (string) and ds (date type). interval_width: float, uncertainty forecast intervals width. StatsForecast’s level \nNotes: You can create automated exogenous variables from the Prophet data processing pipeline these exogenous will be included into AutoARIMA’s exogenous features. Parameters like seasonality_mode, seasonality_prior_scale, holidays_prior_scale, changepoint_prior_scale, mcmc_samples, uncertainty_samples, stan_backend are Prophet exclusive.\nReferences: Sean J. Taylor, Benjamin Letham (2017). “Prophet Forecasting at Scale”\nOskar Triebe, Hansika Hewamalage, Polina Pilyugina, Nikolay Laptev, Christoph Bergmeir, Ram Rajagopal (2021). “NeuralProphet: Explainable Forecasting at Scale”.\nRob J. Hyndman, Yeasmin Khandakar (2008). “Automatic Time Series Forecasting: The forecast package for R”.\n\nsource\n\n\n\n\n AutoARIMAProphet.fit (df, disable_seasonal_features=True, **kwargs)\n\nFit the AutoARIMAProphet adapter.\nParameters: df: pandas.DataFrame, with columns ds (date type) and y, the time series. disable_seasonal_features: bool, Wheter disable Prophet’s seasonal features. kwargs: Additional arguments.\nReturns: self: AutoARIMAProphet adapter object with AutoARIMA fitted model.\n\nsource\n\n\n\n\n AutoARIMAProphet.predict (df=None)\n\nPredict using the AutoARIMAProphet adapter.\nParameters: df: pandas.DataFrame, with columns ds (date type) and y, the time series.\nReturns: fcsts_df: A pandas.DataFrame with the forecast components."
  },
  {
    "objectID": "adapters.prophet.html#univariate-prophet",
    "href": "adapters.prophet.html#univariate-prophet",
    "title": "Replace FB-Prophet",
    "section": "2.1 Univariate Prophet ",
    "text": "2.1 Univariate Prophet \nHere we forecast with Prophet without external regressors. We first instantiate a new Prophet object, and define its forecasting procedure into its constructor. After that a classic sklearn fit and predict is used to obtain the predictions.\n\nm = Prophet(daily_seasonality=False)\nm.fit(df)\nfuture = m.make_future_dataframe(365)\nforecast = m.predict(future)\n\n\nfig = m.plot(forecast)\n\nHere we forecast with AutoARIMAProphet adapter without external regressors. It inherits the Prophet constructor as well as its fit and predict methods.\nWith the class AutoARIMAProphet you can simply substitute Prophet and you’ll be training an AutoARIMA model without changing anything in your forecasting pipeline.\n\nm = AutoARIMAProphet(daily_seasonality=False)\nm.fit(df)\n# m.fit(df, disable_seasonal_features=False) # Uncomment for better AutoARIMA predictions\nfuture = m.make_future_dataframe(365)\nforecast = m.predict(future)\n\n\nfig = m.plot(forecast)"
  },
  {
    "objectID": "adapters.prophet.html#holiday-prophet",
    "href": "adapters.prophet.html#holiday-prophet",
    "title": "Replace FB-Prophet",
    "section": "2.2 Holiday Prophet ",
    "text": "2.2 Holiday Prophet \nUsually Prophet pipelines include the usage of external regressors such as holidays.\nSuppose you want to include holidays or other recurring calendar events, you can create a pandas.DataFrame for them. The DataFrame needs two columns [holiday, ds] and a row for each holiday. It requires all the occurrences of the holiday (as far as the historical data allows) and the future events of the holiday. If the future does not have the holidays registered, they will be modeled but not included in the forecast.\nYou can also include into the events DataFrame, lower_window and upper_window that extends the effect of the holidays through dates to [lower_window, upper_window] days around the date. For example if you wanted to account for Christmas Eve in addition to Christmas you’d include lower_window=-1,upper_window=0, or Black Friday in addition to Thanksgiving, you’d include lower_window=0,upper_window=1.\nHere we Peyton Manning’s playoff appearances dates:\n\nplayoffs = pd.DataFrame({\n  'holiday': 'playoff',\n  'ds': pd.to_datetime(['2008-01-13', '2009-01-03', '2010-01-16',\n                        '2010-01-24', '2010-02-07', '2011-01-08',\n                        '2013-01-12', '2014-01-12', '2014-01-19',\n                        '2014-02-02', '2015-01-11', '2016-01-17',\n                        '2016-01-24', '2016-02-07']),\n  'lower_window': 0,\n  'upper_window': 1,\n})\nsuperbowls = pd.DataFrame({\n  'holiday': 'superbowl',\n  'ds': pd.to_datetime(['2010-02-07', '2014-02-02', '2016-02-07']),\n  'lower_window': 0,\n  'upper_window': 1,\n})\nholidays = pd.concat((playoffs, superbowls))\n\n\nm = Prophet(daily_seasonality=False, holidays=holidays)\nm.add_country_holidays(country_name='US')\nm.fit(df)\nfuture = m.make_future_dataframe(365)\nforecast = m.predict(future)\n\n\nfig = m.plot(forecast)\n\nThe class AutoARIMAProphet adapter allows to handle these scenarios to fit an AutoARIMA model with exogenous variables.\nYou can enjoy your Prophet pipelines with the improved performance of a classic ARIMA.\n\nm = AutoARIMAProphet(daily_seasonality=False,\n                     holidays=holidays)\nm.add_country_holidays(country_name='US')\nm.fit(df)\n# m.fit(df, disable_seasonal_features=False) # Uncomment for better AutoARIMA predictions\nfuture = m.make_future_dataframe(365)\nforecast = m.predict(future)\n\n\nfig = m.plot(forecast)"
  },
  {
    "objectID": "examples/getting_started_with_auto_arima_and_ets.html",
    "href": "examples/getting_started_with_auto_arima_and_ets.html",
    "title": "Getting Started with AutoARIMA and ETS",
    "section": "",
    "text": "Automatic forecasting tools tackle the needs for predictions over large collections of univariate time series that often arise in business practice and other contexts. Among these solutions, R’s forecasting package auto.arima and ets has been a reference for their accuracy and high quality for many years.\nUnfortunately, baselines with their accuracy and computational efficiency were not available for Python yet. For this reason, we developed our new and highly efficient pure-Python implementation of these classic algorithms that we showcase in this notebook.\nIf you are interested in talking about this or other time series models or want to sclae your models in production environments don’t hesitate to send us an email at hello[at]nixtla.io or join our slack community.\nHyndman, RJ and Khandakar, Y (2008) “Automatic time series forecasting: The forecast package for R”, Journal of Statistical Software, 26(3)."
  },
  {
    "objectID": "examples/getting_started_with_auto_arima_and_ets.html#installing-statsforecast-library",
    "href": "examples/getting_started_with_auto_arima_and_ets.html#installing-statsforecast-library",
    "title": "Getting Started with AutoARIMA and ETS",
    "section": "Installing StatsForecast Library",
    "text": "Installing StatsForecast Library\n\n!pip install -U numba\n!pip install -U statsmodels\n!pip install statsforecast\n\n\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display, Markdown\n\nimport matplotlib.pyplot as plt\nfrom statsforecast import StatsForecast\nfrom statsforecast.models import AutoARIMA, ETS\nfrom statsforecast.utils import AirPassengersDF\n\nIf you want to list all avaiaible models run the following lines,\n\n#from statsforecast.models import __all__\n#__all__"
  },
  {
    "objectID": "examples/getting_started_with_auto_arima_and_ets.html#loading-airpassengers-example-data",
    "href": "examples/getting_started_with_auto_arima_and_ets.html#loading-airpassengers-example-data",
    "title": "Getting Started with AutoARIMA and ETS",
    "section": "Loading AirPassengers Example Data",
    "text": "Loading AirPassengers Example Data\n\n# We define the train df. \n# We use the index functionality to make the training a lot faster.\nY_df = AirPassengersDF\nY_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n    \n  \n  \n    \n      0\n      1.0\n      1949-01-31\n      112.0\n    \n    \n      1\n      1.0\n      1949-02-28\n      118.0\n    \n    \n      2\n      1.0\n      1949-03-31\n      132.0\n    \n    \n      3\n      1.0\n      1949-04-30\n      129.0\n    \n    \n      4\n      1.0\n      1949-05-31\n      121.0"
  },
  {
    "objectID": "examples/getting_started_with_auto_arima_and_ets.html#fit-autoarima-and-autoets",
    "href": "examples/getting_started_with_auto_arima_and_ets.html#fit-autoarima-and-autoets",
    "title": "Getting Started with AutoARIMA and ETS",
    "section": "Fit AutoArima and AutoETS",
    "text": "Fit AutoArima and AutoETS\nETS: The exponential smoothing (ETS) algorithm is especially suited for data with seasonality and trend. ETS computes a weighted average over all observations in the input time series dataset as its prediction. In contrast to moving average methods with constant weights, ETS weights exponentially decrease over time, capturing long term dependencies while prioritizing new observations.\nAutoARIMA: The autoregressive integrated moving average (ARIMA), combines differencing steps, lag regression and moving averages into a single method capable of modeling non-stationary time series. This method complements on ETS and it is based on the description of data’s autocorrelations.\n\nY_train_df = Y_df[Y_df.ds<='1959-12-31'] # 132 train\nY_test_df = Y_df[Y_df.ds>'1959-12-31'] # 12 test\n\nDefine the parameters that you want to use in your models. For ETS we pass a ZMZ, model, which stands for error and trend kinds selected optimally. In this step, you could include further models like: SeasonalExponentialSmoothing, ADIDA, HistoricAverage, CrostonClassic, CrostonSBA, CrostonOptimized, SeasonalWindowAverage, SeasonalNaive, IMAPA, Naive, RandomWalkWithDrift, WindowAverage, SeasonalExponentialSmoothing, and TSB.\n\nseason_length = 12\nhorizon = len(Y_test_df)\nmodels = [\n    AutoARIMA(season_length=season_length),\n    ETS(season_length=season_length, model='ZMZ')\n]\nmodel = StatsForecast(\n    df=Y_train_df, \n    models=models,\n    freq='M', \n    n_jobs=-1,\n)\n\nY_hat_df = model.forecast(horizon).reset_index()\nY_hat_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      AutoARIMA\n      ETS\n    \n  \n  \n    \n      0\n      1.0\n      1960-01-31\n      424.160156\n      419.163574\n    \n    \n      1\n      1.0\n      1960-02-29\n      407.081696\n      416.904449\n    \n    \n      2\n      1.0\n      1960-03-31\n      470.860535\n      480.243378\n    \n    \n      3\n      1.0\n      1960-04-30\n      460.913605\n      461.996887\n    \n    \n      4\n      1.0\n      1960-05-31\n      484.900879\n      463.853241"
  },
  {
    "objectID": "examples/getting_started_with_auto_arima_and_ets.html#plot-and-evaluate-predictions",
    "href": "examples/getting_started_with_auto_arima_and_ets.html#plot-and-evaluate-predictions",
    "title": "Getting Started with AutoARIMA and ETS",
    "section": "Plot and Evaluate Predictions",
    "text": "Plot and Evaluate Predictions\nWe are going to plot the models againts the real values of test.\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nY_hat_df = Y_test_df.merge(Y_hat_df, how='left', on=['unique_id', 'ds'])\nplot_df = pd.concat([Y_train_df, Y_hat_df]).set_index('ds')\n\nplot_df[['y', 'AutoARIMA', 'ETS']].plot(ax=ax, linewidth=2)\n\nax.set_title('AirPassengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n\n\n\n\nFinally, we evaluate the predictions accuracy using the Mean Absolute Error:\n\\[\n\\qquad MAE = \\frac{1}{Horizon} \\sum_{\\tau} |y_{\\tau} - \\hat{y}_{\\tau}|\\qquad\n\\]\n\ndef mae(y_hat, y_true):\n    return np.mean(np.abs(y_hat-y_true))\n\ny_true = Y_test_df['y'].values\nets_preds = Y_hat_df['ETS'].values\narima_preds = Y_hat_df['AutoARIMA'].values\n\nprint('ETS   MAE: %0.3f' % mae(ets_preds, y_true))\nprint('ARIMA MAE: %0.3f' % mae(arima_preds, y_true))\n\nETS   MAE: 16.222\nARIMA MAE: 18.551"
  },
  {
    "objectID": "examples/getting_started_with_auto_arima_and_ets.html#add-confidence-intervals-to-arima",
    "href": "examples/getting_started_with_auto_arima_and_ets.html#add-confidence-intervals-to-arima",
    "title": "Getting Started with AutoARIMA and ETS",
    "section": "Add Confidence Intervals to ARIMA",
    "text": "Add Confidence Intervals to ARIMA\nYou just need to add the level argument to the StatsForecast.forecast method as follows,\n\nY_hat_df_intervals = model.forecast(h=12, level=(80, 95))\n\nThen we plot the intervals,\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\ndf_plot = pd.concat([Y_train_df, Y_hat_df_intervals]).set_index('ds')\ndf_plot[['y', 'AutoARIMA','ETS']].plot(ax=ax, linewidth=2)\nax.fill_between(df_plot.index, \n                df_plot['AutoARIMA-lo-80'], \n                df_plot['AutoARIMA-hi-80'],\n                alpha=.35,\n                color='orange',\n                label='auto_arima_level_80')\nax.fill_between(df_plot.index, \n                df_plot['AutoARIMA-lo-95'], \n                df_plot['AutoARIMA-hi-95'],\n                alpha=.2,\n                color='orange',\n                label='auto_arima_level_95')\nax.set_title('AirPassengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\nfor label in (ax.get_xticklabels() + ax.get_yticklabels()):\n    label.set_fontsize(20)"
  },
  {
    "objectID": "examples/getting_started_with_auto_arima_and_ets.html#add-external-regressors-to-arima",
    "href": "examples/getting_started_with_auto_arima_and_ets.html#add-external-regressors-to-arima",
    "title": "Getting Started with AutoARIMA and ETS",
    "section": "Add external regressors to ARIMA",
    "text": "Add external regressors to ARIMA\nFirst we are going to include new exogenous variables as columns to our train data frame. (You can include things like weather or holidays.)\n\nY_train_df['trend'] = np.arange(1, len(Y_train_df) + 1)\nY_train_df['intercept'] = np.ones(len(Y_train_df))\nY_train_df['month'] = Y_train_df['ds'].dt.month\nY_train_df = pd.get_dummies(Y_train_df, columns=['month'], drop_first=True)\n\n\nY_train_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n      trend\n      intercept\n      month_2\n      month_3\n      month_4\n      month_5\n      month_6\n      month_7\n      month_8\n      month_9\n      month_10\n      month_11\n      month_12\n    \n  \n  \n    \n      0\n      1.0\n      1949-01-31\n      112.0\n      1\n      1.0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      1.0\n      1949-02-28\n      118.0\n      2\n      1.0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      1.0\n      1949-03-31\n      132.0\n      3\n      1.0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      1.0\n      1949-04-30\n      129.0\n      4\n      1.0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      1.0\n      1949-05-31\n      121.0\n      5\n      1.0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\nWe consruct the test dataframe of exogenous variables.\n\n# \nxreg_test = pd.DataFrame({\n  'unique_id': 1,\n  'ds': pd.date_range(start='1960-01-01', periods=len(Y_hat_df), freq='M')\n})\n# We construct xreg for test. The train series ends at the 133th step. \nxreg_test['trend'] = np.arange(133, len(Y_hat_df) + 133)\nxreg_test['intercept'] = np.ones(len(Y_hat_df))\nxreg_test['month'] = xreg_test['ds'].dt.month\nxreg_test = pd.get_dummies(xreg_test, columns=['month'], drop_first=True)\nxreg_test.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      trend\n      intercept\n      month_2\n      month_3\n      month_4\n      month_5\n      month_6\n      month_7\n      month_8\n      month_9\n      month_10\n      month_11\n      month_12\n    \n  \n  \n    \n      0\n      1\n      1960-01-31\n      133\n      1.0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      1\n      1960-02-29\n      134\n      1.0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      1\n      1960-03-31\n      135\n      1.0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      1\n      1960-04-30\n      136\n      1.0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      1\n      1960-05-31\n      137\n      1.0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\nseason_length = 12\nmodel = StatsForecast(\n    df=Y_train_df, \n    models=models, \n    freq='M', \n    n_jobs=-1\n)\n\nY_hat_df_xreg = model.forecast(horizon, X_df=xreg_test)\nY_hat_df_xreg = Y_hat_df_xreg.reset_index()\n\nWe are going to plot the models againts the real values of test.\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nY_hat_df_xreg = Y_test_df.merge(Y_hat_df_xreg, how='left', on=['unique_id', 'ds'])\ndf_plot = pd.concat([Y_train_df, Y_hat_df_xreg]).set_index('ds')\ndf_plot[['y', 'AutoARIMA','ETS']].plot(ax=ax, linewidth=2)\nax.set_title('AirPassengers Forecast (with AutoArima external regressors)', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\nfor label in (ax.get_xticklabels() + ax.get_yticklabels()):\n    label.set_fontsize(20)"
  },
  {
    "objectID": "examples/getting_started_with_auto_arima_and_ets.html#include-other-benchmark-models",
    "href": "examples/getting_started_with_auto_arima_and_ets.html#include-other-benchmark-models",
    "title": "Getting Started with AutoARIMA and ETS",
    "section": "Include other Benchmark models",
    "text": "Include other Benchmark models\nWe import more benchmark models as follows,\n\nfrom statsforecast.models import SeasonalNaive, Naive\n\n\nseason_length = 12\nmodels = [\n    AutoARIMA(season_length=12),\n    ETS(season_length=12),\n    SeasonalNaive(season_length=12),\n    Naive()\n]\nmodel = StatsForecast(\n    df=Y_train_df, \n    models=models, \n    freq='M', \n    n_jobs=-1\n)\n\nY_hat_df_bench = model.forecast(horizon, X_df=xreg_test)\nY_hat_df_bench = Y_hat_df_bench.reset_index()\n\nWe are going to plot the models againts the real values of test,\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nY_hat_df_bench = Y_test_df.merge(Y_hat_df_bench, how='left', on=['unique_id', 'ds'])\ndf_plot = pd.concat([Y_train_df, Y_hat_df_bench]).set_index('ds')\ndf_plot[['y', 'AutoARIMA', 'ETS', 'SeasonalNaive', 'Naive']].plot(ax=ax, linewidth=2)\nax.set_title('AirPassengers Forecast (with AutoArima external regressors)', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\nfor label in (ax.get_xticklabels() + ax.get_yticklabels()):\n    label.set_fontsize(20)"
  },
  {
    "objectID": "examples/exogenous.html",
    "href": "examples/exogenous.html",
    "title": "Exogenous Regressors",
    "section": "",
    "text": "With StatsForecast you can easily include exogenous regressors. Some methods, such as AutoARIMA, have the ability to include exogenous regressors, while other models only use the time series information. StatsForecast takes care of passing the exogenous variables to the models that use them."
  },
  {
    "objectID": "examples/exogenous.html#install-statsforecast",
    "href": "examples/exogenous.html#install-statsforecast",
    "title": "Exogenous Regressors",
    "section": "Install statsforecast",
    "text": "Install statsforecast\n\n!pip install statsforecast\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom statsforecast import StatsForecast\nfrom statsforecast.models import AutoARIMA\nfrom statsforecast.utils import AirPassengersDF as Y_df\n\nIn this example, we will use the AirPassengers dataset to show how to work with exogenous regressors.\n\nY_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n    \n  \n  \n    \n      0\n      1.0\n      1949-01-31\n      112.0\n    \n    \n      1\n      1.0\n      1949-02-28\n      118.0\n    \n    \n      2\n      1.0\n      1949-03-31\n      132.0\n    \n    \n      3\n      1.0\n      1949-04-30\n      129.0\n    \n    \n      4\n      1.0\n      1949-05-31\n      121.0"
  },
  {
    "objectID": "examples/exogenous.html#split-traintest-sets",
    "href": "examples/exogenous.html#split-traintest-sets",
    "title": "Exogenous Regressors",
    "section": "Split train/test sets",
    "text": "Split train/test sets\nWe will use the last 12 observations of the dataset as the test set.\n\nhorizon = 12\nY_train_df = Y_df[Y_df.ds<='1959-12-31'] # 132 train\nY_test_df = Y_df[Y_df.ds>'1959-12-31'] # 12 test"
  },
  {
    "objectID": "examples/exogenous.html#add-exogenous-regressors",
    "href": "examples/exogenous.html#add-exogenous-regressors",
    "title": "Exogenous Regressors",
    "section": "Add exogenous regressors",
    "text": "Add exogenous regressors\nIn this example, we will include the trend as exogenous regressor. But you can include as many as you have or want.\n\nY_train_df['trend'] = np.arange(1, len(Y_train_df) + 1)\n\n\nY_train_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n      trend\n    \n  \n  \n    \n      0\n      1.0\n      1949-01-31\n      112.0\n      1\n    \n    \n      1\n      1.0\n      1949-02-28\n      118.0\n      2\n    \n    \n      2\n      1.0\n      1949-03-31\n      132.0\n      3\n    \n    \n      3\n      1.0\n      1949-04-30\n      129.0\n      4\n    \n    \n      4\n      1.0\n      1949-05-31\n      121.0\n      5\n    \n  \n\n\n\n\n\nY_train_df.tail()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n      trend\n    \n  \n  \n    \n      127\n      1.0\n      1959-08-31\n      559.0\n      128\n    \n    \n      128\n      1.0\n      1959-09-30\n      463.0\n      129\n    \n    \n      129\n      1.0\n      1959-10-31\n      407.0\n      130\n    \n    \n      130\n      1.0\n      1959-11-30\n      362.0\n      131\n    \n    \n      131\n      1.0\n      1959-12-31\n      405.0\n      132\n    \n  \n\n\n\n\nObserve that the exogenous regressors have to be placed after the target variable y.\n\nCreate future exogenous regressors\nIn order for the model to produce forecasts, it needs the future exogenous regressors. In this section we will construct a dataframe that includes the future trend.\n\nX_test_df = pd.DataFrame({\n  'unique_id': 1.0,\n  'ds': pd.date_range(start='1960-01-01', periods=horizon, freq='M')\n})\n# We construct xreg for test. The train series ends at the 133th step. \nX_test_df['trend'] = np.arange(133, 133 + horizon)\nX_test_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      trend\n    \n  \n  \n    \n      0\n      1.0\n      1960-01-31\n      133\n    \n    \n      1\n      1.0\n      1960-02-29\n      134\n    \n    \n      2\n      1.0\n      1960-03-31\n      135\n    \n    \n      3\n      1.0\n      1960-04-30\n      136\n    \n    \n      4\n      1.0\n      1960-05-31\n      137"
  },
  {
    "objectID": "examples/exogenous.html#train-the-model",
    "href": "examples/exogenous.html#train-the-model",
    "title": "Exogenous Regressors",
    "section": "Train the model",
    "text": "Train the model\n\nseason_length = 12\nmodel = StatsForecast(\n    df=Y_train_df, \n    models=[AutoARIMA(season_length=12)], \n    freq='M', \n    n_jobs=-1\n)\n\n\nForecast mode\nThe StatsForecast.forecast method is more computationally efficient since it does not save objects during training and predicting. The method receives the future exogenous regressors X_test_df.\n\nY_hat_df = model.forecast(horizon, X_df=X_test_df)\nY_hat_df = Y_hat_df.reset_index()\nY_hat_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      AutoARIMA\n    \n  \n  \n    \n      0\n      1.0\n      1960-01-31\n      414.551483\n    \n    \n      1\n      1.0\n      1960-02-29\n      387.550842\n    \n    \n      2\n      1.0\n      1960-03-31\n      445.526978\n    \n    \n      3\n      1.0\n      1960-04-30\n      431.495422\n    \n    \n      4\n      1.0\n      1960-05-31\n      452.797211\n    \n  \n\n\n\n\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nY_hat_df = Y_test_df.merge(Y_hat_df, how='left', on=['unique_id', 'ds'])\ndf_plot = pd.concat([Y_train_df, Y_hat_df_xreg]).set_index('ds')\ndf_plot[['y', 'AutoARIMA']].plot(ax=ax, linewidth=2)\nax.set_title('AirPassengers Forecast (with AutoARIMA external regressors)', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\nfor label in (ax.get_xticklabels() + ax.get_yticklabels()):\n    label.set_fontsize(20)\n\n\n\n\n\n\nSKlearn syntax\nThe sklearn syntax can also be used. Fist, train the model using the StatsForecast.fit method.\n\nmodel.fit()\n\nStatsForecast(models=[AutoARIMA])\n\n\nThe use the fitted model to produce forecasts. Observe that the StatsForecast.predict method receives the future exogenous regressors.\n\nmodel.predict(horizon, X_df=X_test_df)\n\n\n\n\n\n  \n    \n      \n      ds\n      AutoARIMA\n    \n    \n      unique_id\n      \n      \n    \n  \n  \n    \n      1.0\n      1960-01-31\n      414.551483\n    \n    \n      1.0\n      1960-02-29\n      387.550842\n    \n    \n      1.0\n      1960-03-31\n      445.526978\n    \n    \n      1.0\n      1960-04-30\n      431.495422\n    \n    \n      1.0\n      1960-05-31\n      452.797211\n    \n    \n      1.0\n      1960-06-30\n      502.991394\n    \n    \n      1.0\n      1960-07-31\n      577.782837\n    \n    \n      1.0\n      1960-08-31\n      587.973938\n    \n    \n      1.0\n      1960-09-30\n      491.432617\n    \n    \n      1.0\n      1960-10-31\n      435.070312\n    \n    \n      1.0\n      1960-11-30\n      389.827820\n    \n    \n      1.0\n      1960-12-31\n      432.665527"
  },
  {
    "objectID": "examples/exogenous.html#including-prediction-intervals",
    "href": "examples/exogenous.html#including-prediction-intervals",
    "title": "Exogenous Regressors",
    "section": "Including prediction intervals",
    "text": "Including prediction intervals\nYou can also compute prediction intervals using exogenous regressors. Simply add the level argument.\n\nForecast mode\n\nY_hat_df = model.forecast(horizon, X_df=X_test_df, level=(80,95))\nY_hat_df = Y_hat_df.reset_index()\nY_hat_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      AutoARIMA\n      AutoARIMA-lo-95\n      AutoARIMA-lo-80\n      AutoARIMA-hi-80\n      AutoARIMA-hi-95\n    \n  \n  \n    \n      0\n      1.0\n      1960-01-31\n      414.551483\n      393.468414\n      400.765991\n      428.337006\n      435.634583\n    \n    \n      1\n      1.0\n      1960-02-29\n      387.550842\n      362.181641\n      370.962830\n      404.138855\n      412.920044\n    \n    \n      2\n      1.0\n      1960-03-31\n      445.526978\n      418.457153\n      427.826965\n      463.226990\n      472.596832\n    \n    \n      3\n      1.0\n      1960-04-30\n      431.495422\n      403.697540\n      413.319366\n      449.671478\n      459.293304\n    \n    \n      4\n      1.0\n      1960-05-31\n      452.797211\n      424.679352\n      434.411926\n      471.182495\n      480.915070\n    \n  \n\n\n\n\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\ndf_plot = pd.concat([Y_train_df, Y_hat_df]).set_index('ds')\ndf_plot[['y', 'AutoARIMA']].plot(ax=ax, linewidth=2)\nax.fill_between(df_plot.index, \n                df_plot['AutoARIMA-lo-80'], \n                df_plot['AutoARIMA-hi-80'],\n                alpha=.35,\n                color='orange',\n                label='auto_arima_level_80')\nax.fill_between(df_plot.index, \n                df_plot['AutoARIMA-lo-95'], \n                df_plot['AutoARIMA-hi-95'],\n                alpha=.2,\n                color='orange',\n                label='auto_arima_level_95')\nax.set_title('AirPassengers Forecast (with AutoARIMA external regressors and intervals)', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\nfor label in (ax.get_xticklabels() + ax.get_yticklabels()):\n    label.set_fontsize(20)\n\n\n\n\n\n\nSKlearn syntax\nSince the model is already fitted, just add level=(80,90) to the StatsForecast.predict method.\n\nmodel.predict(horizon, X_df=X_test_df, level=(80, 90))\n\n\n\n\n\n  \n    \n      \n      ds\n      AutoARIMA\n      AutoARIMA-lo-90\n      AutoARIMA-lo-80\n      AutoARIMA-hi-80\n      AutoARIMA-hi-90\n    \n    \n      unique_id\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1.0\n      1960-01-31\n      414.551483\n      396.858002\n      400.765991\n      428.337006\n      432.244995\n    \n    \n      1.0\n      1960-02-29\n      387.550842\n      366.260345\n      370.962830\n      404.138855\n      408.841339\n    \n    \n      1.0\n      1960-03-31\n      445.526978\n      422.809265\n      427.826965\n      463.226990\n      468.244720\n    \n    \n      1.0\n      1960-04-30\n      431.495422\n      408.166718\n      413.319366\n      449.671478\n      454.824127\n    \n    \n      1.0\n      1960-05-31\n      452.797211\n      429.199951\n      434.411926\n      471.182495\n      476.394470\n    \n    \n      1.0\n      1960-06-30\n      502.991394\n      479.274841\n      484.513153\n      521.469604\n      526.707947\n    \n    \n      1.0\n      1960-07-31\n      577.782837\n      554.013000\n      559.263123\n      596.302551\n      601.552612\n    \n    \n      1.0\n      1960-08-31\n      587.973938\n      564.180298\n      569.435669\n      606.512207\n      611.767517\n    \n    \n      1.0\n      1960-09-30\n      491.432617\n      467.628357\n      472.886047\n      509.979187\n      515.236877\n    \n    \n      1.0\n      1960-10-31\n      435.070312\n      411.261261\n      416.520020\n      453.620575\n      458.879333\n    \n    \n      1.0\n      1960-11-30\n      389.827820\n      366.016632\n      371.275848\n      408.379761\n      413.638977\n    \n    \n      1.0\n      1960-12-31\n      432.665527\n      408.853394\n      414.112823\n      451.218231\n      456.477661"
  },
  {
    "objectID": "examples/crossvalidation.html",
    "href": "examples/crossvalidation.html",
    "title": "Cross-validation for Time Series",
    "section": "",
    "text": "Cross-Validation is a widely used technique in data science and machine learning. Most common cross-validation methods require shuffling of the data, and this is why those methods are not applicable to time-series data. The nature of time-series data requires a distinct approach to cross-validation.\nIn this notebook we will give intuition on how time-series cross-validation works. We will be using an example dataset and all the code required to implement the time-series cross-validation with StatsForecast."
  },
  {
    "objectID": "examples/crossvalidation.html#installing-statsforecast-library",
    "href": "examples/crossvalidation.html#installing-statsforecast-library",
    "title": "Cross-validation for Time Series",
    "section": "Installing StatsForecast Library",
    "text": "Installing StatsForecast Library\n\n!pip install -U numba\n!pip install -U statsmodels\n!pip install statsforecast\n!pip install neuralforecast\n\n\nimport random\nfrom itertools import product\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom neuralforecast.losses.numpy import mqloss\nfrom sklearn import metrics\nfrom statsforecast import StatsForecast\nfrom statsforecast.models import AutoARIMA\n\nplt.rcParams[\"figure.figsize\"] = (9,6)\n\n\nAuxiliar plot functions\n\n# Auxiliar plot functions\ndef plot_cv_indices(cv_indices, total_obs, ax, n_splits, lw=10):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n\n    colors = {0:'tab:blue', 1:'tab:orange', 2:'tab:gray'}\n    # Generate the training/testing visualizations for each CV split\n    for ii, (tr, tt) in enumerate(cv_indices):\n        # Fill in indices with the training/test groups\n        indices = np.array([2] * total_obs)\n        indices[tt] = 1\n        indices[tr] = 0\n\n        # Visualize the results\n        ax.scatter(\n            range(len(indices)),\n            [ii + 0.5] * len(indices),\n            c=pd.Series(indices).map(colors),\n            marker=\"_\",\n            lw=lw,\n            # cmap=cmap_cv,\n            vmin=-0.2,\n            vmax=1.2,\n        )\n\n    # Formatting\n    yticklabels = list(range(n_splits))\n    ax.set(\n        yticks=np.arange(n_splits) + 0.5,\n        yticklabels=yticklabels,\n        xlabel=\"Index\",\n        ylabel=\"CV iteration\",\n        ylim=[n_splits, -0.2],\n        xlim=[0, total_obs],\n    )\n    ax.set_title(\"Cross-validation splits\", fontsize=15)\n    return ax\n\ndef plot_grid(df_train, plot_titles, df_test=None, plot_random=True):\n    \"\"\"Plots multiple time series.\"\"\"\n    fig, axes = plt.subplots(4, 2, figsize = (24, 14))\n\n    unique_ids = df_train['unique_id'].unique()\n\n    assert len(unique_ids) >= 8, \"Must provide at least 8 ts\"\n    \n    if plot_random:\n        unique_ids = random.sample(list(unique_ids), k=8)\n    else:\n        unique_uids = unique_ids[:8]\n\n    for uid, (idx, idy) in zip(unique_ids, product(range(4), range(2))):\n        train_uid = df_train.query('unique_id == @uid')\n        axes[idx, idy].plot(train_uid['ds'], train_uid['y'], label = 'y_train', c='black')\n        axes[idx, idy].xaxis.set_tick_params(rotation=45)\n        if df_test is not None:\n            max_ds = train_uid['ds'].max()\n            test_uid = df_test.query('unique_id == @uid')\n            axes[idx, idy].plot(test_uid['ds'], test_uid['y'], c='black', label='True')\n            axes[idx, idy].plot(test_uid['ds'], test_uid['y_5'], c='blue', alpha=0.3)\n            axes[idx, idy].plot(test_uid['ds'], test_uid['y_50'], c='blue', label='p50')\n            axes[idx, idy].plot(test_uid['ds'], test_uid['y_95'], c='blue', alpha=0.3)\n            axes[idx, idy].fill_between(x=test_uid['ds'],\n                                        y1=test_uid['y_5'],\n                                        y2=test_uid['y_95'],\n                                        alpha=0.2, label='p5-p95')\n        axes[idx, idy].set_title(f'State: {plot_titles[uid]}')\n        axes[idx, idy].set_xlabel('Timestamp [t]')\n        axes[idx, idy].set_ylabel('Target')\n        axes[idx, idy].legend(loc='upper left')\n        axes[idx, idy].xaxis.set_major_locator(plt.MaxNLocator(20))\n        axes[idx, idy].grid()\n    fig.subplots_adjust(hspace=0.7)\n    plt.show()"
  },
  {
    "objectID": "examples/crossvalidation.html#time-series-cross-validation",
    "href": "examples/crossvalidation.html#time-series-cross-validation",
    "title": "Cross-validation for Time Series",
    "section": "Time Series Cross-Validation",
    "text": "Time Series Cross-Validation\nIn this procedure there is a series of test sets. The corresponding training sets consist only of observations that ocurred prior to the observations from the test set. Thus, no future observations can be used in constructing the forecast. The following diagram illustrates the series of training and test sets, where the blue observations form the training sets, and the orange observations form the test sets. The forecast accuracy is computed by averaging over the test sets.\nAdapted from https://robjhyndman.com/hyndsight/tscv/\n\ntotal_obs = 100\nnfolds = 10\ncv_indices =[]\n\nfor i in range(1, nfolds+1)[::-1]:\n    cutoff = 100 - i*5\n    cv_indices.append((np.array(range(cutoff)), np.array(range(cutoff, cutoff+5))))\n\nfig, ax = plt.subplots()\nplot_cv_indices(cv_indices, total_obs, ax, nfolds)\n\n<AxesSubplot:title={'center':'Cross-validation splits'}, xlabel='Index', ylabel='CV iteration'>"
  },
  {
    "objectID": "examples/crossvalidation.html#loading-and-exploring-tourism-data",
    "href": "examples/crossvalidation.html#loading-and-exploring-tourism-data",
    "title": "Cross-validation for Time Series",
    "section": "Loading and Exploring Tourism Data",
    "text": "Loading and Exploring Tourism Data\nThe dataset we’ll be using is a tourism dataset containing quarterly data on the number of trips performed during the time span. The trips are categorized by State, Region and Purpose. We’ll be creating predictions at the State level.\n\ndata_url = \"https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv\"\ntourism_df = pd.read_csv(data_url, sep=\",\")\ntourism_df.head()\n\n\n\n\n\n  \n    \n      \n      Quarter\n      Region\n      State\n      Purpose\n      Trips\n    \n  \n  \n    \n      0\n      1998 Q1\n      Adelaide\n      South Australia\n      Business\n      135.077690\n    \n    \n      1\n      1998 Q2\n      Adelaide\n      South Australia\n      Business\n      109.987316\n    \n    \n      2\n      1998 Q3\n      Adelaide\n      South Australia\n      Business\n      166.034687\n    \n    \n      3\n      1998 Q4\n      Adelaide\n      South Australia\n      Business\n      127.160464\n    \n    \n      4\n      1999 Q1\n      Adelaide\n      South Australia\n      Business\n      137.448533\n    \n  \n\n\n\n\n\nPrepare dataset for StatsForecast modelling\n\n# Aggregate\ntarget_var = \"Trips\"\naggregation_vars = [\"Quarter\", \"State\"] \ntourism_df_agg = tourism_df[aggregation_vars + [target_var]].groupby(aggregation_vars, as_index=False).sum()\n\n# Create a dict maping string values in Quarter to datetime\nquarters = tourism_df[\"Quarter\"].sort_values().unique()\nds = pd.date_range(start='1998-01-01', periods=len(quarters), freq='Q')\nds_quarter = dict(zip(quarters, ds))\n\n# Prepare columns\ntourism_df_agg.rename(columns={target_var: 'y'}, inplace=True)\ntourism_df_agg[\"unique_id\"] = tourism_df_agg.groupby(\"State\").ngroup()\ntourism_df_agg[\"ds\"] = [ds_quarter[q] for q in tourism_df_agg[\"Quarter\"]]\n\nState_id = dict(zip(tourism_df_agg[\"unique_id\"].unique(), tourism_df_agg[\"State\"].unique()))\ntourism_df_agg.drop([\"Quarter\", \"State\"], axis=1, inplace=True)\n\n\nplot_grid(tourism_df_agg, plot_titles=State_id)"
  },
  {
    "objectID": "examples/crossvalidation.html#rolling-window-arima-predictions",
    "href": "examples/crossvalidation.html#rolling-window-arima-predictions",
    "title": "Cross-validation for Time Series",
    "section": "Rolling window ARIMA Predictions",
    "text": "Rolling window ARIMA Predictions\n\nPerform Cross-Validation\n\n# Modelling parameters\nseason_length = 4\nhorizon = 1\nfreq = \"Q\"\nn_windows_cv = 20\n\nCreate forecast object and perform cross validation.\n\nfcst = StatsForecast(\n    df=tourism_df_agg, \n    models=[AutoARIMA(season_length=season_length)], \n    freq=freq, \n    n_jobs=-1\n)\nforecasts_cv = fcst.cross_validation(h=horizon, n_windows=n_windows_cv, level=(90,)) \nforecasts_cv.head()\n\n\n\n\n\n  \n    \n      \n      ds\n      cutoff\n      y\n      AutoARIMA\n      AutoARIMA-lo-90\n      AutoARIMA-hi-90\n    \n    \n      unique_id\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      0\n      2013-03-31\n      2012-12-31\n      524.553589\n      485.676483\n      382.970947\n      588.381958\n    \n    \n      0\n      2013-06-30\n      2013-03-31\n      475.532501\n      486.325409\n      384.189240\n      588.461609\n    \n    \n      0\n      2013-09-30\n      2013-06-30\n      506.512085\n      486.145721\n      384.876953\n      587.414490\n    \n    \n      0\n      2013-12-31\n      2013-09-30\n      529.584534\n      486.476532\n      385.993347\n      586.959717\n    \n    \n      0\n      2014-03-31\n      2013-12-31\n      540.607544\n      487.153168\n      387.096008\n      587.210327\n    \n  \n\n\n\n\nPlot time series CV.\n\ntime_cv_indices = [\n    (np.where(ds <= cutoff), np.where(ds == cutoff) + np.array(1)) \\\n    for cutoff in forecasts_cv[forecasts_cv.index == 0][\"cutoff\"]\n]\n\nfig, ax = plt.subplots()\nplot_cv_indices(time_cv_indices, tourism_df_agg[tourism_df_agg.unique_id == 0].shape[0], ax, n_windows_cv)\n\n<AxesSubplot:title={'center':'Cross-validation splits'}, xlabel='Index', ylabel='CV iteration'>\n\n\n\n\n\n\n\nQuantitative evaluation\nFor the evaluation we use the Mean Absolute Error:\n\\[ \\mathrm{MAE}(y, \\hat{y}) = \\frac{1}{N*H} \\sum_{i,\\tau} |y_{i,\\tau}-\\hat{y}_{i,\\tau}| \\]\n\ndef compute_MAE(df, model_name):\n    return metrics.mean_absolute_error(df[\"y\"], df[model_name])\n\ncutoff_values = forecasts_cv[\"cutoff\"].unique()\ncv_MAE = []\nfor ct in cutoff_values:\n    cv_MAE.append(compute_MAE(forecasts_cv[forecasts_cv[\"cutoff\"] == ct], \"AutoARIMA\"))\nprint(f\"Average Mean Absolute Error across all Cross-Validation folds: {str(np.round(np.mean(cv_MAE), decimals=2))}\")\n\nAverage Mean Absolute Error across all Cross-Validation folds: 172.65\n\n\n\n\nPlotting predictions\n\nforecasts_cv.rename(\n    columns={\"AutoARIMA\": \"y_50\", \"AutoARIMA-lo-90\": \"y_5\", \"AutoARIMA-hi-90\": \"y_95\"}, \n    inplace=True\n)\nplot_grid(tourism_df_agg, plot_titles=State_id, df_test=forecasts_cv)"
  },
  {
    "objectID": "examples/installation.html",
    "href": "examples/installation.html",
    "title": "Installation",
    "section": "",
    "text": "Conda\nAlso you can install the released version of StatsForecast from conda with:\nconda install -c conda-forge statsforecast\n(Installing inside a python virtualenvironment or a conda environment is recommended.)"
  },
  {
    "objectID": "examples/prophet_spark_m5.html",
    "href": "examples/prophet_spark_m5.html",
    "title": "StatsForecast ETS and Facebook Prophet on Spark (M5)",
    "section": "",
    "text": "The purpose of this notebook is to create a scalability benchmark (time and performance). To that end, Nixtla’s StatsForecast (using the ETS model) is trained on the M5 dataset using spark to distribute the training. As a comparison, Facebook’s Prophet model is used.\nAn AWS cluster (mounted on databricks) of 11 instances of type m5.2xlarge (8 cores, 32 GB RAM) with runtime 10.4 LTS was used. This notebook was used as base case.\nThe example uses the M5 dataset. It consists of 30,490 bottom time series."
  },
  {
    "objectID": "examples/prophet_spark_m5.html#main-results",
    "href": "examples/prophet_spark_m5.html#main-results",
    "title": "StatsForecast ETS and Facebook Prophet on Spark (M5)",
    "section": "Main results",
    "text": "Main results\n\n\n\nMethod\nTime (mins)\nPerformance (wRMSSE)\n\n\n\n\nStatsForecast\n7.5\n0.68\n\n\nProphet\n18.23\n0.77"
  },
  {
    "objectID": "examples/prophet_spark_m5.html#installing-libraries",
    "href": "examples/prophet_spark_m5.html#installing-libraries",
    "title": "StatsForecast ETS and Facebook Prophet on Spark (M5)",
    "section": "Installing libraries",
    "text": "Installing libraries\n\npip install prophet \"neuralforecast<1.0.0\" \"statsforecast[fugue]\""
  },
  {
    "objectID": "examples/prophet_spark_m5.html#statsforecast-pipeline",
    "href": "examples/prophet_spark_m5.html#statsforecast-pipeline",
    "title": "StatsForecast ETS and Facebook Prophet on Spark (M5)",
    "section": "StatsForecast pipeline",
    "text": "StatsForecast pipeline\n\nfrom time import time\n\nfrom neuralforecast.data.datasets.m5 import M5, M5Evaluation\nfrom statsforecast.distributed.utils import forecast\nfrom statsforecast.distributed.fugue import FugueBackend\nfrom statsforecast.models import ETS, SeasonalNaive\nfrom statsforecast.core import StatsForecast\n\nfrom pyspark.sql import SparkSession\n\n\n\n\n\n\nspark = SparkSession.builder.getOrCreate()\nbackend = FugueBackend(spark, {\"fugue.spark.use_pandas_udf\":True})\n\n\n\n\n\n\nForecast\nWith statsforecast you don’t have to download your data. The distributed backend can handle a file with your data.\n\ninit = time()\nets_forecasts = backend.forecast(\n    \"s3://m5-benchmarks/data/train/m5-target.parquet\", \n    [ETS(season_length=7, model='ZAA')], \n    freq=\"D\", \n    h=28, \n).toPandas()\nend = time()\nprint(f'Minutes taken by StatsForecast on a Spark cluster: {(end - init) / 60}')\n\n\nMinutes taken by StatsForecast on a Spark cluster: 7.471468730767568\n\n\n\n\n\nEvaluating performance\nThe M5 competition used the weighted root mean squared scaled error. You can find details of the metric here.\n\nY_hat = ets_forecasts.set_index(['unique_id', 'ds']).unstack()\nY_hat = Y_hat.droplevel(0, 1).reset_index()\n\n\n\n\n\n\n*_, S_df = M5.load('./data')\nY_hat = S_df.merge(Y_hat, how='left', on=['unique_id'])#.drop(columns=['unique_id'])\n\n\nwrmsse_ets = M5Evaluation.evaluate(y_hat=Y_hat, directory='./data')\n\n\nwrmsse_ets\n\n\nOut[14]: \n\n\n\n\n\n\n  \n    \n      \n      wrmsse\n    \n  \n  \n    \n      Total\n      0.682358\n    \n    \n      Level1\n      0.449115\n    \n    \n      Level2\n      0.533754\n    \n    \n      Level3\n      0.592317\n    \n    \n      Level4\n      0.497086\n    \n    \n      Level5\n      0.572189\n    \n    \n      Level6\n      0.593880\n    \n    \n      Level7\n      0.665358\n    \n    \n      Level8\n      0.652183\n    \n    \n      Level9\n      0.734492\n    \n    \n      Level10\n      1.012633\n    \n    \n      Level11\n      0.969902\n    \n    \n      Level12\n      0.915380"
  },
  {
    "objectID": "examples/prophet_spark_m5.html#prophet-pipeline",
    "href": "examples/prophet_spark_m5.html#prophet-pipeline",
    "title": "StatsForecast ETS and Facebook Prophet on Spark (M5)",
    "section": "Prophet pipeline",
    "text": "Prophet pipeline\n\nimport logging\nfrom time import time\n\nimport pandas as pd\nfrom neuralforecast.data.datasets.m5 import M5, M5Evaluation\nfrom prophet import Prophet\nfrom pyspark.sql.types import *\n\n# disable informational messages from prophet\nlogging.getLogger('py4j').setLevel(logging.ERROR)\n\n\nINFO:py4j.java_gateway:Received command c on object id p0\nINFO:py4j.java_gateway:Received command c on object id p0\nINFO:py4j.java_gateway:Received command c on object id p0\nINFO:py4j.java_gateway:Received command c on object id p0\nINFO:py4j.java_gateway:Received command c on object id p0\nINFO:py4j.java_gateway:Received command c on object id p0\nINFO:py4j.java_gateway:Received command c on object id p0\nINFO:py4j.java_gateway:Received command c on object id p0\nINFO:py4j.java_gateway:Received command c on object id p0\nINFO:py4j.java_gateway:Received command c on object id p0\n\n\n\n\nDownload data\n\n# structure of the training data set\ntrain_schema = StructType([\n  StructField('unique_id', StringType()),  \n  StructField('ds', DateType()),\n  StructField('y', DoubleType())\n  ])\n \n# read the training file into a dataframe\ntrain = spark.read.parquet(\n  's3://m5-benchmarks/data/train/m5-target.parquet', \n  header=True, \n  schema=train_schema\n )\n \n# make the dataframe queriable as a temporary view\ntrain.createOrReplaceTempView('train')\n\n\n\n\n\n\nsql_statement = '''\n  SELECT\n    unique_id AS unique_id,\n    CAST(ds as date) as ds,\n    y as y\n  FROM train\n  '''\n \nm5_history = (\n  spark\n    .sql( sql_statement )\n    .repartition(sc.defaultParallelism, ['unique_id'])\n  ).cache()\n\n\n\n\n\n\n\nForecast function using Prophet\n\ndef forecast( history_pd: pd.DataFrame ) -> pd.DataFrame:\n  \n  # TRAIN MODEL AS BEFORE\n  # --------------------------------------\n  # remove missing values (more likely at day-store-item level)\n    history_pd = history_pd.dropna()\n\n    # configure the model\n    model = Prophet(\n        growth='linear',\n        daily_seasonality=False,\n        weekly_seasonality=True,\n        yearly_seasonality=True,\n        seasonality_mode='multiplicative'\n    )\n\n    # train the model\n    model.fit( history_pd )\n    # --------------------------------------\n\n    # BUILD FORECAST AS BEFORE\n    # --------------------------------------\n    # make predictions\n    future_pd = model.make_future_dataframe(\n        periods=28, \n        freq='d', \n        include_history=False\n    )\n    forecast_pd = model.predict( future_pd )  \n    # --------------------------------------\n\n    # ASSEMBLE EXPECTED RESULT SET\n    # --------------------------------------\n    # get relevant fields from forecast\n    forecast_pd['unique_id'] = history_pd['unique_id'].unique()[0]\n    f_pd = forecast_pd[['unique_id', 'ds','yhat']]\n    # --------------------------------------\n\n    # return expected dataset\n    return f_pd\n\n\n\n\n\n\nresult_schema = StructType([\n  StructField('unique_id', StringType()), \n  StructField('ds',DateType()),\n  StructField('yhat',FloatType()),\n])\n\n\n\n\n\n\nTraining Prophet on the M5 dataset\n\ninit = time()\nresults = (\n  m5_history\n    .groupBy('unique_id')\n      .applyInPandas(forecast, schema=result_schema)\n    ).toPandas()\nend = time()\nprint(f'Minutes taken by Prophet on a Spark cluster: {(end - init) / 60}')\n\n\nMinutes taken by Prophet on a Spark cluster: 18.23116923570633\n\n\n\n\n\n\nEvaluating performance\nThe M5 competition used the weighted root mean squared scaled error. You can find details of the metric here.\n\nY_hat = results.set_index(['unique_id', 'ds']).unstack()\nY_hat = Y_hat.droplevel(0, 1).reset_index()\n\n\n\n\n\n\n*_, S_df = M5.load('./data')\nY_hat = S_df.merge(Y_hat, how='left', on=['unique_id'])#.drop(columns=['unique_id'])\n\n\n\n\n\n\nwrmsse = M5Evaluation.evaluate(y_hat=Y_hat, directory='./data')\n\n\n\n\n\n\nwrmsse\n\n\nOut[10]: \n\n\n\n\n\n\n  \n    \n      \n      wrmsse\n    \n  \n  \n    \n      Total\n      0.771800\n    \n    \n      Level1\n      0.507905\n    \n    \n      Level2\n      0.586328\n    \n    \n      Level3\n      0.666686\n    \n    \n      Level4\n      0.549358\n    \n    \n      Level5\n      0.655003\n    \n    \n      Level6\n      0.647176\n    \n    \n      Level7\n      0.747047\n    \n    \n      Level8\n      0.743422\n    \n    \n      Level9\n      0.824667\n    \n    \n      Level10\n      1.207069\n    \n    \n      Level11\n      1.108780\n    \n    \n      Level12\n      1.018163"
  },
  {
    "objectID": "examples/ets_ray_m5.html",
    "href": "examples/ets_ray_m5.html",
    "title": "Forecasting at Scale using ETS and ray (M5)",
    "section": "",
    "text": "In this notebook we show how to use StatsForecast and ray to forecast thounsands of time series in less than 6 minutes (M5 dataset). Also, we show that StatsForecast has better performance in time and accuracy compared to Prophet running on a Spark cluster using DataBricks.\nIn this example, we used a ray cluster (AWS) of 11 instances of type m5.2xlarge (8 cores, 32 GB RAM)."
  },
  {
    "objectID": "examples/ets_ray_m5.html#installing-statsforecast-library",
    "href": "examples/ets_ray_m5.html#installing-statsforecast-library",
    "title": "Forecasting at Scale using ETS and ray (M5)",
    "section": "Installing StatsForecast Library",
    "text": "Installing StatsForecast Library\n\n!pip install \"statsforecast[ray]\" neuralforecast s3fs pyarrow\n\n\nfrom time import time\n\nimport pandas as pd\nfrom neuralforecast.data.datasets.m5 import M5, M5Evaluation\nfrom statsforecast import StatsForecast\nfrom statsforecast.models import ETS"
  },
  {
    "objectID": "examples/ets_ray_m5.html#download-data",
    "href": "examples/ets_ray_m5.html#download-data",
    "title": "Forecasting at Scale using ETS and ray (M5)",
    "section": "Download data",
    "text": "Download data\nThe example uses the M5 dataset. It consists of 30,490 bottom time series.\n\nY_df = pd.read_parquet('s3://m5-benchmarks/data/train/target.parquet')\nY_df = Y_df.rename(columns={\n    'item_id': 'unique_id', \n    'timestamp': 'ds', \n    'demand': 'y'\n})\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\n\n\nY_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n    \n  \n  \n    \n      0\n      FOODS_1_001_CA_1\n      2011-01-29\n      3.0\n    \n    \n      1\n      FOODS_1_001_CA_1\n      2011-01-30\n      0.0\n    \n    \n      2\n      FOODS_1_001_CA_1\n      2011-01-31\n      0.0\n    \n    \n      3\n      FOODS_1_001_CA_1\n      2011-02-01\n      1.0\n    \n    \n      4\n      FOODS_1_001_CA_1\n      2011-02-02\n      4.0\n    \n  \n\n\n\n\nSince the M5 dataset contains intermittent time series, we add a constant to avoid problems during the training phase. Later, we will substract the constant from the forecasts.\n\nconstant = 10\nY_df['y'] += constant"
  },
  {
    "objectID": "examples/ets_ray_m5.html#train-the-model",
    "href": "examples/ets_ray_m5.html#train-the-model",
    "title": "Forecasting at Scale using ETS and ray (M5)",
    "section": "Train the model",
    "text": "Train the model\nStatsForecast receives a list of models to fit each time series. Since we are dealing with Daily data, it would be benefitial to use 7 as seasonality. Observe that we need to pass the ray address to the ray_address argument.\n\nfcst = StatsForecast(\n    df=Y_df, \n    models=[ETS(season_length=7, model='ZNA')], \n    freq='D', \n    #n_jobs=-1\n    ray_address='ray://ADDRESS:10001'\n)\n\n\ninit = time()\nY_hat = fcst.forecast(28)\nend = time()\nprint(f'Minutes taken by StatsForecast using: {(end - init) / 60}')\n\n/home/ubuntu/miniconda/envs/ray/lib/python3.7/site-packages/ray/util/client/worker.py:618: UserWarning: More than 10MB of messages have been created to schedule tasks on the server. This can be slow on Ray Client due to communication overhead over the network. If you're running many fine-grained tasks, consider running them inside a single remote function. See the section on \"Too fine-grained tasks\" in the Ray Design Patterns document for more details: https://docs.google.com/document/d/167rnnDFIVRhHhK4mznEIemOtj63IOhtIPvSYaPgI4Fg/edit#heading=h.f7ins22n6nyl. If your functions frequently use large objects, consider storing the objects remotely with ray.put. An example of this is shown in the \"Closure capture of large / unserializable object\" section of the Ray Design Patterns document, available here: https://docs.google.com/document/d/167rnnDFIVRhHhK4mznEIemOtj63IOhtIPvSYaPgI4Fg/edit#heading=h.1afmymq455wu\n  UserWarning,\n\n\nMinutes taken by StatsForecast using: 5.4817593971888225\n\n\nStatsForecast and ray took only 5.48 minutes to train 30,490 time series, compared to 18.23 minutes for Prophet and Spark.\nWe remove the constant.\n\nY_hat['ETS'] -= constant\n\n\nEvaluating performance\nThe M5 competition used the weighted root mean squared scaled error. You can find details of the metric here.\n\nY_hat = Y_hat.reset_index().set_index(['unique_id', 'ds']).unstack()\nY_hat = Y_hat.droplevel(0, 1).reset_index()\n\n\n*_, S_df = M5.load('./data')\nY_hat = S_df.merge(Y_hat, how='left', on=['unique_id'])\n\n100%|███████████████████████████████████████████████████████████| 50.2M/50.2M [00:00<00:00, 77.1MiB/s]\n\n\n\nM5Evaluation.evaluate(y_hat=Y_hat, directory='./data')\n\n\n\n\n\n  \n    \n      \n      wrmsse\n    \n  \n  \n    \n      Total\n      0.677233\n    \n    \n      Level1\n      0.435558\n    \n    \n      Level2\n      0.522863\n    \n    \n      Level3\n      0.582109\n    \n    \n      Level4\n      0.488484\n    \n    \n      Level5\n      0.567825\n    \n    \n      Level6\n      0.587605\n    \n    \n      Level7\n      0.662774\n    \n    \n      Level8\n      0.647712\n    \n    \n      Level9\n      0.732107\n    \n    \n      Level10\n      1.013124\n    \n    \n      Level11\n      0.970465\n    \n    \n      Level12\n      0.916175\n    \n  \n\n\n\n\nAlso, StatsForecast is more accurate than Prophet, since the overall WMRSSE is 0.68, against 0.77 obtained by prophet."
  },
  {
    "objectID": "examples/anomalydetection.html#installing-statsforecast-library",
    "href": "examples/anomalydetection.html#installing-statsforecast-library",
    "title": "Anomaly Detection",
    "section": "Installing StatsForecast Library",
    "text": "Installing StatsForecast Library\n\n!pip install statsforecast neuralforecast\n\n\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom itertools import product\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom ipywidgets import interact\nfrom statsforecast import StatsForecast\nfrom statsforecast.models import AutoARIMA\n\n\nUseful functions\nThe plot_grid function defined below will be useful to plot different time series, and different models’ forecasts.\n\ndef plot_grid(df_train, df_test=None, plot_random=True, level=None, anomalies=False):\n    fig, axes = plt.subplots(4, 2, figsize = (24, 14))\n\n    unique_ids = df_train['unique_id'].unique()\n\n    assert len(unique_ids) >= 8, \"Must provide at least 8 ts\"\n    \n    if plot_random:\n        unique_ids = random.sample(list(unique_ids), k=8)\n    else:\n        unique_uids = unique_ids[:8]\n\n    for uid, (idx, idy) in zip(unique_ids, product(range(4), range(2))):\n        train_uid = df_train.query('unique_id == @uid')\n        axes[idx, idy].plot(train_uid['ds'], train_uid['y'], label = 'y_train')\n        if level is not None and anomalies: \n            axes[idx, idy].fill_between(\n                train_uid['ds'], \n                train_uid[f'AutoARIMA-lo-{level}'], \n                train_uid[f'AutoARIMA-hi-{level}'],\n                alpha=0.9,\n                color='orange',\n                label=f'AutoARIMA_level_{level}',\n            )\n            filt = (train_uid['y'] > train_uid[f'AutoARIMA-hi-{level}']) | (train_uid[f'AutoARIMA-lo-{level}'] > train_uid['y'])\n            anomalies_df = train_uid[filt][['ds', 'y']]\n            axes[idx, idy].scatter(\n                anomalies_df['ds'],\n                anomalies_df['y'],\n                color='red',\n                label='Anomalies'\n            )\n        if df_test is not None:\n            max_ds = train_uid['ds'].max()\n            test_uid = df_test.query('unique_id == @uid')\n            models = df_test.drop(['unique_id', 'ds'], axis=1).columns\n            for model in models:\n                if all(np.isnan(test_uid[model])):\n                    continue\n                if 'lo' in model or 'hi' in model:\n                    continue\n                axes[idx, idy].plot(test_uid['ds'], test_uid[model], label=model)\n            if level is not None:\n                for l in level:\n                    axes[idx, idy].fill_between(\n                        test_uid['ds'], \n                        test_uid[f'AutoARIMA-lo-{l}'], \n                        test_uid[f'AutoARIMA-hi-{l}'],\n                        alpha=1 - l // 100,\n                        color='orange',\n                        label=f'AutoARIMA_level_{l}',\n                    )\n        axes[idx, idy].set_title(f'M4 Hourly: {uid}')\n        axes[idx, idy].set_xlabel('Timestamp [t]')\n        axes[idx, idy].set_ylabel('Target')\n        axes[idx, idy].legend(loc='upper left')\n        axes[idx, idy].xaxis.set_major_locator(plt.MaxNLocator(20))\n        axes[idx, idy].grid()\n    fig.subplots_adjust(hspace=0.5)\n    plt.show()"
  },
  {
    "objectID": "examples/anomalydetection.html#download-data",
    "href": "examples/anomalydetection.html#download-data",
    "title": "Anomaly Detection",
    "section": "Download data",
    "text": "Download data\nFor testing purposes, we will use the Hourly dataset from the M4 competition.\n\n!wget https://auto-arima-results.s3.amazonaws.com/M4-Hourly.csv\n\n\ntrain = pd.read_csv('M4-Hourly.csv')\n\nIn this example we will use a subset of the data to avoid waiting too long. You can modify the number of series if you want.\n\nn_series = 8\nuids = train['unique_id'].unique()[:n_series]\ntrain = train.query('unique_id in @uids')\n\n\nplot_grid(train)"
  },
  {
    "objectID": "examples/anomalydetection.html#train-the-model",
    "href": "examples/anomalydetection.html#train-the-model",
    "title": "Anomaly Detection",
    "section": "Train the model",
    "text": "Train the model\nStatsForecast receives a list of models to fit each time series. Since we are dealing with Hourly data, it would be benefitial to use 24 as seasonality.\n\nmodels = [AutoARIMA(season_length=24, approximation=True)]\n\n\nfcst = StatsForecast(df=train, \n                     models=models, \n                     freq='H', \n                     n_jobs=-1)\n\nWe can define the level of the forecast intervals we want to produce. StatsForecast will produce these levels for both forecasts and intra-sample forecasts.\n\nlevels = [80, 90, 95, 99]\n\nObserve that we need to pass fitted=True to the forecast method to recover the insample forecasts.\n\nforecasts = fcst.forecast(h=48, fitted=True, level=levels)\n\n\nforecasts = forecasts.reset_index()\n\n\nforecasts.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      AutoARIMA\n      AutoARIMA-lo-99\n      AutoARIMA-lo-95\n      AutoARIMA-lo-90\n      AutoARIMA-lo-80\n      AutoARIMA-hi-80\n      AutoARIMA-hi-90\n      AutoARIMA-hi-95\n      AutoARIMA-hi-99\n    \n  \n  \n    \n      0\n      H1\n      701\n      616.084167\n      585.106445\n      592.513000\n      596.302612\n      600.671814\n      631.496460\n      635.865662\n      639.655273\n      647.061890\n    \n    \n      1\n      H1\n      702\n      544.432129\n      494.394348\n      506.358063\n      512.479370\n      519.536865\n      569.327393\n      576.384888\n      582.506165\n      594.469910\n    \n    \n      2\n      H1\n      703\n      510.414490\n      443.625366\n      459.594238\n      467.764801\n      477.184906\n      543.644043\n      553.064148\n      561.234741\n      577.203613\n    \n    \n      3\n      H1\n      704\n      481.046539\n      404.228729\n      422.595398\n      431.992798\n      442.827393\n      519.265686\n      530.100281\n      539.497681\n      557.864380\n    \n    \n      4\n      H1\n      705\n      460.893066\n      378.863678\n      398.476410\n      408.511383\n      420.081024\n      501.705109\n      513.274780\n      523.309692\n      542.922424\n    \n  \n\n\n\n\n\nplot_grid(train, forecasts)"
  },
  {
    "objectID": "examples/anomalydetection.html#recover-insample-forecasts",
    "href": "examples/anomalydetection.html#recover-insample-forecasts",
    "title": "Anomaly Detection",
    "section": "Recover insample forecasts",
    "text": "Recover insample forecasts\nOnce the model is fitted, we can recover the insample forecasts and their prediction intervals using forecast_fitted_values.\n\ninsample_forecasts = fcst.forecast_fitted_values().reset_index()\n\n\ninsample_forecasts.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n      AutoARIMA\n      AutoARIMA-lo-99\n      AutoARIMA-lo-95\n      AutoARIMA-lo-90\n      AutoARIMA-lo-80\n      AutoARIMA-hi-80\n      AutoARIMA-hi-90\n      AutoARIMA-hi-95\n      AutoARIMA-hi-99\n    \n  \n  \n    \n      0\n      H1\n      1\n      605.0\n      604.395020\n      573.417297\n      580.823853\n      584.613464\n      588.982666\n      619.807312\n      624.176514\n      627.966125\n      635.372742\n    \n    \n      1\n      H1\n      2\n      586.0\n      585.414001\n      554.436279\n      561.842896\n      565.632507\n      570.001648\n      600.826355\n      605.195557\n      608.985168\n      616.391724\n    \n    \n      2\n      H1\n      3\n      586.0\n      585.414001\n      554.436279\n      561.842896\n      565.632507\n      570.001709\n      600.826355\n      605.195557\n      608.985168\n      616.391724\n    \n    \n      3\n      H1\n      4\n      559.0\n      558.441040\n      527.463318\n      534.869873\n      538.659485\n      543.028687\n      573.853333\n      578.222534\n      582.012146\n      589.418762\n    \n    \n      4\n      H1\n      5\n      511.0\n      510.489014\n      479.511292\n      486.917877\n      490.707520\n      495.076691\n      525.901367\n      530.270569\n      534.060181\n      541.466736"
  },
  {
    "objectID": "examples/anomalydetection.html#plot-anomalies",
    "href": "examples/anomalydetection.html#plot-anomalies",
    "title": "Anomaly Detection",
    "section": "Plot anomalies",
    "text": "Plot anomalies\nIn this example, we consider as an anomaly an observation that is above the upper prediction interval or below the lower prediction interval of a certain probability level.\n\nplot_grid(insample_forecasts, level=99, anomalies=True)\n\n\n\n\nThe following code, allows us to inspect the anomalies in detail.\n\nuid = \"H1\"\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\ndf_plot = insample_forecasts.query('unique_id == @uid')[:60]\nax.plot(df_plot['ds'], df_plot['y'], linewidth=2)\nax.fill_between(df_plot['ds'], \n                df_plot['AutoARIMA-lo-99'], \n                df_plot['AutoARIMA-hi-99'],\n                alpha=.35,\n                color='orange',\n                label='AutoARIMA_level_99')\nanomalies_df = df_plot.query('y > `AutoARIMA-hi-99` or y < `AutoARIMA-lo-99`')[['ds', 'y']]\nax.scatter(\n    anomalies_df['ds'],\n    anomalies_df['y'],\n    color='red',\n    label='Anomalies',\n    s=100\n)\nax.set_title(f'{uid} Anomalies', fontsize=22)\nax.set_ylabel('Target', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\nfor label in (ax.get_xticklabels() + ax.get_yticklabels()):\n    label.set_fontsize(20)\n\n\n\n\n\nWidget\nWe can also create a widget to change the probability level of the prediction intervals.\n\n@interact(level=reversed(levels))\ndef plot_anomalies(level):\n    plot_grid(insample_forecasts, level=level, anomalies=True)"
  },
  {
    "objectID": "examples/uncertaintyintervals.html#installing-statsforecast-library",
    "href": "examples/uncertaintyintervals.html#installing-statsforecast-library",
    "title": "Prediction Intervals",
    "section": "Installing StatsForecast Library",
    "text": "Installing StatsForecast Library\n\n!pip install statsforecast\n\n\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom itertools import product\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom ipywidgets import interact\nfrom statsforecast import StatsForecast\nfrom statsforecast.models import (\n    AutoARIMA, SeasonalNaive, Naive, \n    RandomWalkWithDrift, HistoricAverage\n)\n\n\nUseful functions\nThe plot_grid function defined below will be useful to plot different time series, and different models’ forecasts.\n\ndef plot_grid(df_train, df_test=None, plot_random=True, model=None, level=None):\n    fig, axes = plt.subplots(4, 2, figsize = (24, 14))\n\n    unique_ids = df_train['unique_id'].unique()\n\n    assert len(unique_ids) >= 8, \"Must provide at least 8 ts\"\n    \n    if plot_random:\n        unique_ids = random.sample(list(unique_ids), k=8)\n    else:\n        unique_uids = unique_ids[:8]\n\n    for uid, (idx, idy) in zip(unique_ids, product(range(4), range(2))):\n        train_uid = df_train.query('unique_id == @uid')\n        axes[idx, idy].plot(train_uid['ds'], train_uid['y'], label = 'y_train')\n        if df_test is not None:\n            max_ds = train_uid['ds'].max()\n            test_uid = df_test.query('unique_id == @uid')\n            for col in ['y', model, 'y_test']:\n                if col in test_uid:\n                    axes[idx, idy].plot(test_uid['ds'], test_uid[col], label=col)\n            if level is not None:\n                for l, alpha in zip(sorted(level), [0.5, .4, .35, .2]):\n                    axes[idx, idy].fill_between(\n                        test_uid['ds'], \n                        test_uid[f'{model}-lo-{l}'], \n                        test_uid[f'{model}-hi-{l}'],\n                        alpha=alpha,\n                        color='orange',\n                        label=f'{model}_level_{l}',\n                    )\n        axes[idx, idy].set_title(f'M4 Hourly: {uid}')\n        axes[idx, idy].set_xlabel('Timestamp [t]')\n        axes[idx, idy].set_ylabel('Target')\n        axes[idx, idy].legend(loc='upper left')\n        axes[idx, idy].xaxis.set_major_locator(plt.MaxNLocator(20))\n        axes[idx, idy].grid()\n    fig.subplots_adjust(hspace=0.5)\n    plt.show()"
  },
  {
    "objectID": "examples/uncertaintyintervals.html#download-data",
    "href": "examples/uncertaintyintervals.html#download-data",
    "title": "Prediction Intervals",
    "section": "Download data",
    "text": "Download data\nFor testing purposes, we will use the Hourly dataset from the M4 competition.\n\n!wget https://auto-arima-results.s3.amazonaws.com/M4-Hourly.csv\n!wget https://auto-arima-results.s3.amazonaws.com/M4-Hourly-test.csv\n\n\ntrain = pd.read_csv('M4-Hourly.csv')\ntest = pd.read_csv('M4-Hourly-test.csv').rename(columns={'y': 'y_test'})\n\nIn this example we will use a subset of the data to avoid waiting too long. You can modify the number of series if you want.\n\nn_series = 8\nuids = train['unique_id'].unique()[:n_series]\ntrain = train.query('unique_id in @uids')\ntest = test.query('unique_id in @uids')\n\n\nplot_grid(train, test)"
  },
  {
    "objectID": "examples/uncertaintyintervals.html#train-the-model",
    "href": "examples/uncertaintyintervals.html#train-the-model",
    "title": "Prediction Intervals",
    "section": "Train the model",
    "text": "Train the model\nStatsForecast receives a list of models to fit each time series. Since we are dealing with Hourly data, it would be benefitial to use 24 as seasonality.\n\nmodels = [\n    AutoARIMA(season_length=24, approximation=True),\n    Naive(),\n    SeasonalNaive(season_length=24),\n    RandomWalkWithDrift(),\n    HistoricAverage()\n]\n\n\nfcst = StatsForecast(df=train, \n                     models=models, \n                     freq='H', \n                     n_jobs=-1)\n\nWe can define the level of the forecast intervals we want to produce. StatsForecast will produce these levels.\n\nlevels = [80, 90, 95, 99]\n\n\nforecasts = fcst.forecast(h=48, level=levels)\n\n\nforecasts = forecasts.reset_index()\n\n\nforecasts.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      AutoARIMA\n      AutoARIMA-lo-99\n      AutoARIMA-lo-95\n      AutoARIMA-lo-90\n      AutoARIMA-lo-80\n      AutoARIMA-hi-80\n      AutoARIMA-hi-90\n      AutoARIMA-hi-95\n      ...\n      RWD-hi-99\n      HistoricAverage\n      HistoricAverage-lo-80\n      HistoricAverage-lo-90\n      HistoricAverage-lo-95\n      HistoricAverage-lo-99\n      HistoricAverage-hi-80\n      HistoricAverage-hi-90\n      HistoricAverage-hi-95\n      HistoricAverage-hi-99\n    \n  \n  \n    \n      0\n      H1\n      701\n      616.084167\n      585.106445\n      592.513000\n      596.302612\n      600.671814\n      631.496460\n      635.865662\n      639.655273\n      ...\n      789.416626\n      638.488586\n      436.697418\n      379.492432\n      329.875641\n      232.90242\n      840.279724\n      897.484741\n      947.101562\n      1044.074707\n    \n    \n      1\n      H1\n      702\n      544.432129\n      494.394348\n      506.358063\n      512.479370\n      519.536865\n      569.327393\n      576.384888\n      582.506165\n      ...\n      833.254150\n      638.488586\n      436.697418\n      379.492432\n      329.875641\n      232.90242\n      840.279724\n      897.484741\n      947.101562\n      1044.074707\n    \n    \n      2\n      H1\n      703\n      510.414490\n      443.625366\n      459.594238\n      467.764801\n      477.184906\n      543.644043\n      553.064148\n      561.234741\n      ...\n      866.990601\n      638.488586\n      436.697418\n      379.492432\n      329.875641\n      232.90242\n      840.279724\n      897.484741\n      947.101562\n      1044.074707\n    \n    \n      3\n      H1\n      704\n      481.046539\n      404.228729\n      422.595398\n      431.992798\n      442.827393\n      519.265686\n      530.100281\n      539.497681\n      ...\n      895.510132\n      638.488586\n      436.697418\n      379.492432\n      329.875641\n      232.90242\n      840.279724\n      897.484741\n      947.101562\n      1044.074707\n    \n    \n      4\n      H1\n      705\n      460.893066\n      378.863678\n      398.476410\n      408.511383\n      420.081024\n      501.705109\n      513.274780\n      523.309692\n      ...\n      920.702881\n      638.488586\n      436.697418\n      379.492432\n      329.875641\n      232.90242\n      840.279724\n      897.484741\n      947.101562\n      1044.074707\n    \n  \n\n5 rows × 47 columns\n\n\n\n\ntest = test.merge(forecasts, how='left', on=['unique_id', 'ds'])"
  },
  {
    "objectID": "examples/uncertaintyintervals.html#plot-prediction-intervals",
    "href": "examples/uncertaintyintervals.html#plot-prediction-intervals",
    "title": "Prediction Intervals",
    "section": "Plot prediction intervals",
    "text": "Plot prediction intervals\nThen we can plot the prediction intervals for each model as follows.\n\nAutoARIMA\n\nplot_grid(train, test, level=levels, model='AutoARIMA')\n\n\n\n\n\n\nSeasonal Naive\n\nplot_grid(train, test, level=levels, model='SeasonalNaive')\n\n\n\n\n\n\nHistoric Average\n\nplot_grid(train, test, level=levels, model='HistoricAverage')\n\n\n\n\n\n\nNaive\n\nplot_grid(train, test, level=levels, model='Naive')\n\n\n\n\n\n\nRandom Walk with Drift\n\nplot_grid(train, test, level=levels, model='RWD')"
  },
  {
    "objectID": "examples/contributing.html",
    "href": "examples/contributing.html",
    "title": "How to Contribute",
    "section": "",
    "text": "Ensure the bug was not already reported by searching on GitHub under Issues.\nIf you’re unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behavior that is not occurring.\nBe sure to add the complete error messages."
  },
  {
    "objectID": "examples/contributing.html#do-you-have-a-feature-request",
    "href": "examples/contributing.html#do-you-have-a-feature-request",
    "title": "How to Contribute",
    "section": "Do you have a feature request?",
    "text": "Do you have a feature request?\n\nEnsure that it hasn’t been yet implemented in the main branch of the repository and that there’s not an Issue requesting it yet.\nOpen a new issue and make sure to describe it clearly, mention how it improves the project and why its useful."
  },
  {
    "objectID": "examples/contributing.html#do-you-want-to-fix-a-bug-or-implement-a-feature",
    "href": "examples/contributing.html#do-you-want-to-fix-a-bug-or-implement-a-feature",
    "title": "How to Contribute",
    "section": "Do you want to fix a bug or implement a feature?",
    "text": "Do you want to fix a bug or implement a feature?\nBug fixes and features are added through pull requests (PRs)."
  },
  {
    "objectID": "examples/contributing.html#pr-submission-guidelines",
    "href": "examples/contributing.html#pr-submission-guidelines",
    "title": "How to Contribute",
    "section": "PR submission guidelines",
    "text": "PR submission guidelines\n\nKeep each PR focused. While it’s more convenient, do not combine several unrelated fixes together. Create as many branches as needing to keep each PR focused.\nEnsure that your PR includes a test that fails without your patch, and passes with it.\nEnsure the PR description clearly describes the problem and solution. Include the relevant issue number if applicable.\nDo not mix style changes/fixes with “functional” changes. It’s very difficult to review such PRs and it most likely get rejected.\nDo not add/remove vertical whitespace. Preserve the original style of the file you edit as much as you can.\nDo not turn an already submitted PR into your development playground. If after you submitted PR, you discovered that more work is needed - close the PR, do the required work and then submit a new PR. Otherwise each of your commits requires attention from maintainers of the project.\nIf, however, you submitted a PR and received a request for changes, you should proceed with commits inside that PR, so that the maintainer can see the incremental fixes and won’t need to review the whole PR again. In the exception case where you realize it’ll take many many commits to complete the requests, then it’s probably best to close the PR, do the work and then submit it again. Use common sense where you’d choose one way over another.\n\n\nLocal setup for working on a PR\n\n1. Clone the repository\n\nHTTPS: git clone https://github.com/Nixtla/statsforecast.git\nSSH: git clone git@github.com:Nixtla/statsforecast.git\nGitHub CLI: gh repo clone Nixtla/statsforecast\n\n\n\n2. Set up a conda environment\nThe repo comes with an environment.yml file which contains the libraries needed to run all the tests. In order to set up the environment you must have conda installed, we recommend miniconda.\nOnce you have conda go to the top level directory of the repository and run:\nconda env create -f environment.yml\n\n\n3. Install the library\nOnce you have your environment setup, activate it using conda activate statsforecast and then install the library in editable mode using pip install -e \".[dev]\"\n\n\n4. Install git hooks\nBefore doing any changes to the code, please install the git hooks that run automatic scripts during each commit and merge to strip the notebooks of superfluous metadata (and avoid merge conflicts).\nnbdev_install_hooks\n\n\n\nBuilding the library\nThe library is built using the notebooks contained in the nbs folder. If you want to make any changes to the library you have to find the relevant notebook, make your changes and then call nbdev_export.\n\n\nRunning tests\nIf you’re working on the local interface you can just use nbdev_test.\n\n\nLinters\nThis project uses a couple of linters to validate different aspects of the code. Before opening a PR, please make sure that it passes all the linting tasks by following the next steps.\n\nRun the linting tasks\n\nmypy statsforecast/\nflake8 --select=F statsforecast/\n\n\n\n\nCleaning notebooks\nSince the notebooks output cells can vary from run to run (even if they produce the same outputs) the notebooks are cleaned before committing them. Please make sure to run nbdev_clean before committing your changes."
  },
  {
    "objectID": "examples/contributing.html#do-you-want-to-contribute-to-the-documentation",
    "href": "examples/contributing.html#do-you-want-to-contribute-to-the-documentation",
    "title": "How to Contribute",
    "section": "Do you want to contribute to the documentation?",
    "text": "Do you want to contribute to the documentation?\n\nDocs are automatically created from the notebooks in the nbs folder.\nIn order to modify the documentation:\n\nFind the relevant notebook.\nMake your changes.\nRun all cells.\nIf you are modifying library notebooks (not in nbs/examples), clean all outputs using Edit > Clear All Outputs.\nRun nbdev_preview."
  },
  {
    "objectID": "examples/intermittentdata.html",
    "href": "examples/intermittentdata.html",
    "title": "Forecasting Intermitent Time Series",
    "section": "",
    "text": "Sparse or intermittent series are series with very few non-zero observations. They are notoriously hard to forecast, and so, different methods have been developed especifically for them.\nIn this notebook we’ll implement and benchmark some of the most popular methods for intermitent forecast using the StatsForecast library."
  },
  {
    "objectID": "examples/intermittentdata.html#installing-statsforecast-library",
    "href": "examples/intermittentdata.html#installing-statsforecast-library",
    "title": "Forecasting Intermitent Time Series",
    "section": "Installing StatsForecast Library",
    "text": "Installing StatsForecast Library\n\n!pip install -U numba\n!pip install -U statsmodels\n!pip install statsforecast\n!pip install neuralforecast\n\n\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom itertools import product\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom neuralforecast.data.datasets import m5\nfrom statsforecast import StatsForecast\nfrom statsforecast.models import (\n    ADIDA, CrostonClassic, CrostonOptimized,\n    CrostonSBA, IMAPA, TSB, ETS, AutoARIMA\n)\n\nplt.rcParams[\"figure.figsize\"] = (9,6)\n\n\nPlot functions\n\ndef plot_grid(df_train, plot_titles, model_cols=[\"y_50\"], df_test=None, plot_random=True):\n    \"\"\"Plots multiple time series.\"\"\"\n    fig, axes = plt.subplots(4, 2, figsize = (24, 14))\n\n    unique_ids = df_train['unique_id'].unique()\n\n    assert len(unique_ids) >= 8, \"Must provide at least 8 ts\"\n    \n    if plot_random:\n        unique_ids = random.sample(list(unique_ids), k=8)\n    else:\n        unique_uids = unique_ids[:8]\n\n    for uid, (idx, idy) in zip(unique_ids, product(range(4), range(2))):\n        train_uid = df_train.query('unique_id == @uid')\n        axes[idx, idy].plot(train_uid['ds'], train_uid['y'], label = 'y_train', c='black')\n        axes[idx, idy].xaxis.set_tick_params(rotation=45)\n        if df_test is not None:\n            max_ds = train_uid['ds'].max()\n            test_uid = df_test.query('unique_id == @uid')\n            axes[idx, idy].plot(test_uid['ds'], test_uid['y'], c='black', label='True')\n\n            for col in model_cols:\n                axes[idx, idy].plot(test_uid['ds'], test_uid[col], label=col)\n\n        axes[idx, idy].set_title(f'State: {plot_titles[uid]}')\n        axes[idx, idy].set_xlabel('Timestamp [t]')\n        axes[idx, idy].set_ylabel('Target')\n        axes[idx, idy].legend(loc='upper left')\n        axes[idx, idy].xaxis.set_major_locator(plt.MaxNLocator(20))\n        axes[idx, idy].grid()\n    fig.subplots_adjust(hspace=0.7)\n    plt.show()"
  },
  {
    "objectID": "examples/intermittentdata.html#loading-and-exploring-the-m5-dataset",
    "href": "examples/intermittentdata.html#loading-and-exploring-the-m5-dataset",
    "title": "Forecasting Intermitent Time Series",
    "section": "Loading and Exploring the M5 Dataset",
    "text": "Loading and Exploring the M5 Dataset\nThe M5 dataset consists of real-life data from Walmart and was used on a competition conducted on Kaggle. The data consists of around 42,000 hierarchical daily time series, starting at the level of SKUs and ending with the total demand of some large geographical area.\n\nY_df_total, *_ = m5.M5.load('./data')\n\n\nprint(Y_df_total['unique_id'].nunique())\nY_df_total.head()\n\n30490\n\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n    \n  \n  \n    \n      0\n      FOODS_1_001_CA_1\n      2011-01-29\n      3.0\n    \n    \n      1\n      FOODS_1_001_CA_1\n      2011-01-30\n      0.0\n    \n    \n      2\n      FOODS_1_001_CA_1\n      2011-01-31\n      0.0\n    \n    \n      3\n      FOODS_1_001_CA_1\n      2011-02-01\n      1.0\n    \n    \n      4\n      FOODS_1_001_CA_1\n      2011-02-02\n      4.0\n    \n  \n\n\n\n\n\nPrepare dataset for StatsForecast modelling\n\nCreate a subset of the dataset\n\nids = random.sample(list(Y_df_total['unique_id'].unique()), 100)\n\nY_df = Y_df_total.query('unique_id in @ids')\n\nY_df[\"unique_id\"] = Y_df[\"unique_id\"].astype(str)\n\nY_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n    \n  \n  \n    \n      573344\n      FOODS_1_035_CA_1\n      2011-01-29\n      3.0\n    \n    \n      573345\n      FOODS_1_035_CA_1\n      2011-01-30\n      5.0\n    \n    \n      573346\n      FOODS_1_035_CA_1\n      2011-01-31\n      1.0\n    \n    \n      573347\n      FOODS_1_035_CA_1\n      2011-02-01\n      0.0\n    \n    \n      573348\n      FOODS_1_035_CA_1\n      2011-02-02\n      0.0\n    \n  \n\n\n\n\n\nplot_titles = dict(zip(ids, ids))\nplot_grid(Y_df, plot_titles=plot_titles)"
  },
  {
    "objectID": "examples/intermittentdata.html#modelling-intermitent-data",
    "href": "examples/intermittentdata.html#modelling-intermitent-data",
    "title": "Forecasting Intermitent Time Series",
    "section": "Modelling intermitent data",
    "text": "Modelling intermitent data\n\nADIDA: Temporal aggregation is used for reducing the presence of zero observations, thus mitigating the undesirable effect of the variance observed in the intervals. ADIDA uses equally sized time buckets to perform non-overlapping temporal aggregation and predict the demand over a pre-specified lead-time.\niMAPA: iMAPA stands for Intermittent Multiple Aggregation Prediction Algorithm. Another way for implementing temporal aggregation in demand forecasting. However, in contrast to ADIDA that considers a single aggregation level, iMAPA considers multiple ones, aiming at capturing different dynamics of the data\nTSB: TSB stands for Teunter-Syntetos-Babai. A modification to Croston’s method that replaces the inter-demand intervals component with the demand probability.\n\n\n# Split train test\nY_train_df = Y_df[Y_df.ds <= '2016-06-12']\nY_test_df = Y_df[Y_df.ds > '2016-06-12']\nprint(f\"Train: {Y_train_df.ds.nunique()}\")\nprint(f\"Test: {Y_test_df.ds.nunique()}\")\n\nTrain: 1962\nTest: 7\n\n\n\nmodels = [ADIDA(), IMAPA(), TSB(alpha_d=0.2, alpha_p=0.2)]\nhorizon = 7\nfreq = \"D\"\n\n\n# Create the forecast object and forecast test set\nmodel = StatsForecast(df=Y_train_df, models=models, freq=freq, n_jobs=-1)\n\nY_hat_df = model.forecast(horizon).reset_index()\nY_hat_df.head()\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      ADIDA\n      IMAPA\n      TSB\n    \n  \n  \n    \n      0\n      FOODS_1_035_CA_1\n      2016-06-13\n      2.153789\n      2.233399\n      2.424801\n    \n    \n      1\n      FOODS_1_035_CA_1\n      2016-06-14\n      2.153789\n      2.233399\n      2.424801\n    \n    \n      2\n      FOODS_1_035_CA_1\n      2016-06-15\n      2.153789\n      2.233399\n      2.424801\n    \n    \n      3\n      FOODS_1_035_CA_1\n      2016-06-16\n      2.153789\n      2.233399\n      2.424801\n    \n    \n      4\n      FOODS_1_035_CA_1\n      2016-06-17\n      2.153789\n      2.233399\n      2.424801\n    \n  \n\n\n\n\n\nY_test_df\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      y\n    \n  \n  \n    \n      575306\n      FOODS_1_035_CA_1\n      2016-06-13\n      0.0\n    \n    \n      575307\n      FOODS_1_035_CA_1\n      2016-06-14\n      1.0\n    \n    \n      575308\n      FOODS_1_035_CA_1\n      2016-06-15\n      0.0\n    \n    \n      575309\n      FOODS_1_035_CA_1\n      2016-06-16\n      4.0\n    \n    \n      575310\n      FOODS_1_035_CA_1\n      2016-06-17\n      2.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      46805207\n      HOUSEHOLD_2_460_CA_1\n      2016-06-15\n      0.0\n    \n    \n      46805208\n      HOUSEHOLD_2_460_CA_1\n      2016-06-16\n      0.0\n    \n    \n      46805209\n      HOUSEHOLD_2_460_CA_1\n      2016-06-17\n      1.0\n    \n    \n      46805210\n      HOUSEHOLD_2_460_CA_1\n      2016-06-18\n      0.0\n    \n    \n      46805211\n      HOUSEHOLD_2_460_CA_1\n      2016-06-19\n      0.0\n    \n  \n\n700 rows × 3 columns"
  },
  {
    "objectID": "examples/intermittentdata.html#model-evaluation",
    "href": "examples/intermittentdata.html#model-evaluation",
    "title": "Forecasting Intermitent Time Series",
    "section": "Model Evaluation",
    "text": "Model Evaluation\n\nQuantitative evaluation\nFor the evaluation we use the Mean Absolute Error\n\\[ \\mathrm{MAE}(y, \\hat{y}) = \\frac{1}{N*H} \\sum_{i,\\tau} |y_{i,\\tau}-\\hat{y}_{i,\\tau}| \\]\n\ndef mae(y_hat, y_true):\n    return np.mean(np.abs(y_hat-y_true))\n\ny_true = Y_test_df['y'].values\nadida_preds = Y_hat_df['ADIDA'].values\nimapa_preds = Y_hat_df['IMAPA'].values\ntsb_preds = Y_hat_df['TSB'].values\n\nprint('ADIDA MAE: \\t %0.3f' % mae(adida_preds, y_true))\nprint('iMAPA MAE: \\t %0.3f' % mae(imapa_preds, y_true))\nprint('TSB   MAE: \\t %0.3f' % mae(tsb_preds, y_true))\n\nADIDA MAE:   1.172\niMAPA MAE:   1.173\nTSB   MAE:   1.180\n\n\n\n\nPlotting predictions\n\nY_hat_df\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      ADIDA\n      IMAPA\n      TSB\n    \n  \n  \n    \n      0\n      FOODS_1_035_CA_1\n      2016-06-13\n      2.153789\n      2.233399\n      2.424801\n    \n    \n      1\n      FOODS_1_035_CA_1\n      2016-06-14\n      2.153789\n      2.233399\n      2.424801\n    \n    \n      2\n      FOODS_1_035_CA_1\n      2016-06-15\n      2.153789\n      2.233399\n      2.424801\n    \n    \n      3\n      FOODS_1_035_CA_1\n      2016-06-16\n      2.153789\n      2.233399\n      2.424801\n    \n    \n      4\n      FOODS_1_035_CA_1\n      2016-06-17\n      2.153789\n      2.233399\n      2.424801\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      695\n      HOUSEHOLD_2_460_CA_1\n      2016-06-15\n      0.075524\n      0.059694\n      0.083630\n    \n    \n      696\n      HOUSEHOLD_2_460_CA_1\n      2016-06-16\n      0.075524\n      0.059694\n      0.083630\n    \n    \n      697\n      HOUSEHOLD_2_460_CA_1\n      2016-06-17\n      0.075524\n      0.059694\n      0.083630\n    \n    \n      698\n      HOUSEHOLD_2_460_CA_1\n      2016-06-18\n      0.075524\n      0.059694\n      0.083630\n    \n    \n      699\n      HOUSEHOLD_2_460_CA_1\n      2016-06-19\n      0.075524\n      0.059694\n      0.083630\n    \n  \n\n700 rows × 5 columns\n\n\n\n\nY_test_df = Y_test_df.merge(Y_hat_df, how='left', on=['unique_id', 'ds'])\n\nplot_grid(Y_train_df.groupby('unique_id').tail(3*horizon), \n          plot_titles=plot_titles, \n          model_cols=['ADIDA', 'IMAPA', 'TSB'], \n          df_test=Y_test_df)"
  },
  {
    "objectID": "examples/autoarima_vs_prophet.html#motivation",
    "href": "examples/autoarima_vs_prophet.html#motivation",
    "title": "AutoARIMA Comparison (Prophet and pmdarima)",
    "section": "Motivation",
    "text": "Motivation\nThe AutoARIMA model is widely used to forecast time series in production and as a benchmark. However, the python implementation (pmdarima) is so slow that prevent data scientist practioners from quickly iterating and deploying AutoARIMA in production for a large number of time series. In this notebook we present Nixtla’s AutoARIMA based on the R implementation (developed by Rob Hyndman) and optimized using numba."
  },
  {
    "objectID": "examples/autoarima_vs_prophet.html#example",
    "href": "examples/autoarima_vs_prophet.html#example",
    "title": "AutoARIMA Comparison (Prophet and pmdarima)",
    "section": "Example",
    "text": "Example\n\nLibraries\n\n!pip install statsforecast prophet statsmodels sklearn matplotlib pmdarima\n\n\nimport logging\nimport os\nimport random\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom itertools import product\nfrom multiprocessing import cpu_count, Pool # for prophet\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom pmdarima import auto_arima as auto_arima_p\nfrom prophet import Prophet\nfrom statsforecast import StatsForecast\nfrom statsforecast.models import AutoARIMA, _TS\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom sklearn.model_selection import ParameterGrid\n\nImporting plotly failed. Interactive plots will not work.\n\n\n\nUseful functions\nThe plot_grid function defined below will be useful to plot different time series, and different models’ forecasts.\n\ndef plot_grid(df_train, df_test=None, plot_random=True):\n    fig, axes = plt.subplots(4, 2, figsize = (24, 14))\n\n    unique_ids = df_train['unique_id'].unique()\n\n    assert len(unique_ids) >= 8, \"Must provide at least 8 ts\"\n    \n    if plot_random:\n        unique_ids = random.sample(list(unique_ids), k=8)\n    else:\n        unique_uids = unique_ids[:8]\n\n    for uid, (idx, idy) in zip(unique_ids, product(range(4), range(2))):\n        train_uid = df_train.query('unique_id == @uid')\n        axes[idx, idy].plot(train_uid['ds'], train_uid['y'], label = 'y_train')\n        if df_test is not None:\n            max_ds = train_uid['ds'].max()\n            test_uid = df_test.query('unique_id == @uid')\n            for model in df_test.drop(['unique_id', 'ds'], axis=1).columns:\n                if all(np.isnan(test_uid[model])):\n                    continue\n                axes[idx, idy].plot(test_uid['ds'], test_uid[model], label=model)\n\n        axes[idx, idy].set_title(f'M4 Hourly: {uid}')\n        axes[idx, idy].set_xlabel('Timestamp [t]')\n        axes[idx, idy].set_ylabel('Target')\n        axes[idx, idy].legend(loc='upper left')\n        axes[idx, idy].xaxis.set_major_locator(plt.MaxNLocator(20))\n        axes[idx, idy].grid()\n    fig.subplots_adjust(hspace=0.5)\n    plt.show()\n\n\ndef plot_autocorrelation_grid(df_train):\n    fig, axes = plt.subplots(4, 2, figsize = (24, 14))\n\n    unique_ids = df_train['unique_id'].unique()\n\n    assert len(unique_ids) >= 8, \"Must provide at least 8 ts\"\n\n    unique_ids = random.sample(list(unique_ids), k=8)\n\n    for uid, (idx, idy) in zip(unique_ids, product(range(4), range(2))):\n        train_uid = df_train.query('unique_id == @uid')\n        plot_acf(train_uid['y'].values, ax=axes[idx, idy], \n                 title=f'ACF M4 Hourly {uid}')\n        axes[idx, idy].set_xlabel('Timestamp [t]')\n        axes[idx, idy].set_ylabel('Autocorrelation')\n    fig.subplots_adjust(hspace=0.5)\n    plt.show()\n\n\n\n\nData\nFor testing purposes, we will use the Hourly dataset from the M4 competition.\n\n!wget https://auto-arima-results.s3.amazonaws.com/M4-Hourly.csv\n\n\n!wget https://auto-arima-results.s3.amazonaws.com/M4-Hourly-test.csv\n\n\ntrain = pd.read_csv('M4-Hourly.csv')\ntest = pd.read_csv('M4-Hourly-test.csv').rename(columns={'y': 'y_test'})\n\nIn this example we will use a subset of the data to avoid waiting too long. You can modify the number of series if you want.\n\nn_series = 16\nuids = train['unique_id'].unique()[:n_series]\ntrain = train.query('unique_id in @uids')\ntest = test.query('unique_id in @uids')\n\n\nplot_grid(train, test)\n\n\n\n\nWould an autorregresive model be the right choice for our data? There is no doubt that we observe seasonal periods. The autocorrelation function (acf) can help us to answer the question. Intuitively, we have to observe a decreasing correlation to opt for an AR model.\n\nplot_autocorrelation_grid(train)\n\n\n\n\nThus, we observe a high autocorrelation for previous lags and also for the seasonal lags. Therefore, we will let auto_arima to handle our data.\n\n\nTraining and forecasting\nStatsForecast receives a list of models to fit each time series. Since we are dealing with Hourly data, it would be benefitial to use 24 as seasonality.\n\n?AutoARIMA\n\n\nInit signature:\nAutoARIMA(\n    d: Optional[int] = None,\n    D: Optional[int] = None,\n    max_p: int = 5,\n    max_q: int = 5,\n    max_P: int = 2,\n    max_Q: int = 2,\n    max_order: int = 5,\n    max_d: int = 2,\n    max_D: int = 1,\n    start_p: int = 2,\n    start_q: int = 2,\n    start_P: int = 1,\n    start_Q: int = 1,\n    stationary: bool = False,\n    seasonal: bool = True,\n    ic: str = 'aicc',\n    stepwise: bool = True,\n    nmodels: int = 94,\n    trace: bool = False,\n    approximation: Optional[bool] = False,\n    method: Optional[str] = None,\n    truncate: Optional[bool] = None,\n    test: str = 'kpss',\n    test_kwargs: Optional[str] = None,\n    seasonal_test: str = 'seas',\n    seasonal_test_kwargs: Optional[Dict] = None,\n    allowdrift: bool = False,\n    allowmean: bool = False,\n    blambda: Optional[float] = None,\n    biasadj: bool = False,\n    parallel: bool = False,\n    num_cores: int = 2,\n    season_length: int = 1,\n)\nDocstring:      <no docstring>\nFile:           ~/fede/statsforecast/statsforecast/models.py\nType:           type\nSubclasses:     \n\n\n\n\nAs we see, we can pass season_length to AutoARIMA, so the definition of our models would be,\n\nmodels = [AutoARIMA(season_length=24, approximation=True)]\n\n\nfcst = StatsForecast(df=train, \n                     models=models, \n                     freq='H', \n                     n_jobs=-1)\n\n\ninit = time.time()\nforecasts = fcst.forecast(48)\nend = time.time()\n\ntime_nixtla = end - init\ntime_nixtla\n\n20.36360502243042\n\n\n\nforecasts.head()\n\n\n\n\n\n  \n    \n      \n      ds\n      AutoARIMA\n    \n    \n      unique_id\n      \n      \n    \n  \n  \n    \n      H1\n      701\n      616.084167\n    \n    \n      H1\n      702\n      544.432129\n    \n    \n      H1\n      703\n      510.414490\n    \n    \n      H1\n      704\n      481.046539\n    \n    \n      H1\n      705\n      460.893066\n    \n  \n\n\n\n\n\nforecasts = forecasts.reset_index()\n\n\ntest = test.merge(forecasts, how='left', on=['unique_id', 'ds'])\n\n\nplot_grid(train, test)"
  },
  {
    "objectID": "examples/autoarima_vs_prophet.html#alternatives",
    "href": "examples/autoarima_vs_prophet.html#alternatives",
    "title": "AutoARIMA Comparison (Prophet and pmdarima)",
    "section": "Alternatives",
    "text": "Alternatives\n\npmdarima\nYou can use the StatsForecast class to parallelize your own models. In this section we will use it to run the auto_arima model from pmdarima.\n\nclass PMDAutoARIMA(_TS):\n    \n    def __init__(self, season_length: int):\n        self.season_length = season_length\n        \n    def forecast(self, y, h, X=None, X_future=None, fitted=False):\n        mod = auto_arima_p(\n            y, m=self.season_length,\n            with_intercept=False #ensure comparability with Nixtla's implementation\n        ) \n        return {'mean': mod.predict(h)}\n    \n    def __repr__(self):\n        return 'pmdarima'\n\n\nn_series_pmdarima = 2\n\n\nfcst = StatsForecast(\n    df = train.query('unique_id in [\"H1\", \"H10\"]'), \n    models=[PMDAutoARIMA(season_length=24)],\n    freq='H',\n    n_jobs=-1\n)\n\n\ninit = time.time()\nforecast_pmdarima = fcst.forecast(48)\nend = time.time()\n\ntime_pmdarima = end - init\ntime_pmdarima\n\n349.93623208999634\n\n\n\nforecast_pmdarima.head()\n\n\n\n\n\n  \n    \n      \n      ds\n      pmdarima\n    \n    \n      unique_id\n      \n      \n    \n  \n  \n    \n      H1\n      701\n      627.479370\n    \n    \n      H1\n      702\n      570.364380\n    \n    \n      H1\n      703\n      541.831482\n    \n    \n      H1\n      704\n      516.475647\n    \n    \n      H1\n      705\n      503.044586\n    \n  \n\n\n\n\n\nforecast_pmdarima = forecast_pmdarima.reset_index()\n\n\ntest = test.merge(forecast_pmdarima, how='left', on=['unique_id', 'ds'])\n\n\nplot_grid(train, test, plot_random=False)\n\n\n\n\n\n\nProphet\nProphet is designed to receive a pandas dataframe, so we cannot use StatForecast. Therefore, we need to parallize from scratch.\n\nparams_grid = {'seasonality_mode': ['multiplicative','additive'],\n               'growth': ['linear', 'flat'], \n               'changepoint_prior_scale': [0.1, 0.2, 0.3, 0.4, 0.5], \n               'n_changepoints': [5, 10, 15, 20]} \ngrid = ParameterGrid(params_grid)\n\n\ndef fit_and_predict(index, ts):\n    df = ts.drop(columns='unique_id', axis=1)\n    max_ds = df['ds'].max()\n    df['ds'] = pd.date_range(start='1970-01-01', periods=df.shape[0], freq='H')\n    df_val = df.tail(48) \n    df_train = df.drop(df_val.index) \n    y_val = df_val['y'].values\n    \n    if len(df_train) >= 48:\n        val_results = {'losses': [], 'params': []}\n\n        for params in grid:\n            model = Prophet(seasonality_mode=params['seasonality_mode'],\n                            growth=params['growth'],\n                            weekly_seasonality=True,\n                            daily_seasonality=True,\n                            yearly_seasonality=True,\n                            n_changepoints=params['n_changepoints'],\n                            changepoint_prior_scale=params['changepoint_prior_scale'])\n            model = model.fit(df_train)\n            \n            forecast = model.make_future_dataframe(periods=48, \n                                                   include_history=False, \n                                                   freq='H')\n            forecast = model.predict(forecast)\n            forecast['unique_id'] = index\n            forecast = forecast.filter(items=['unique_id', 'ds', 'yhat'])\n            \n            loss = np.mean(abs(y_val - forecast['yhat'].values))\n            \n            val_results['losses'].append(loss)\n            val_results['params'].append(params)\n\n        idx_params = np.argmin(val_results['losses']) \n        params = val_results['params'][idx_params]\n    else:\n        params = {'seasonality_mode': 'multiplicative',\n                  'growth': 'flat',\n                  'n_changepoints': 150,\n                  'changepoint_prior_scale': 0.5}\n    model = Prophet(seasonality_mode=params['seasonality_mode'],\n                    growth=params['growth'],\n                    weekly_seasonality=True,\n                    daily_seasonality=True,\n                    yearly_seasonality=True,\n                    n_changepoints=params['n_changepoints'],\n                    changepoint_prior_scale=params['changepoint_prior_scale'])\n    model = model.fit(df)\n    \n    forecast = model.make_future_dataframe(periods=48, \n                                           include_history=False, \n                                           freq='H')\n    forecast = model.predict(forecast)\n    forecast.insert(0, 'unique_id', index)\n    forecast['ds'] = np.arange(max_ds + 1, max_ds + 48 + 1)\n    forecast = forecast.filter(items=['unique_id', 'ds', 'yhat'])\n    \n    return forecast\n\n\nlogging.getLogger('prophet').setLevel(logging.WARNING)\n\n\nclass suppress_stdout_stderr(object):\n    '''\n    A context manager for doing a \"deep suppression\" of stdout and stderr in\n    Python, i.e. will suppress all print, even if the print originates in a\n    compiled C/Fortran sub-function.\n       This will not suppress raised exceptions, since exceptions are printed\n    to stderr just before a script exits, and after the context manager has\n    exited (at least, I think that is why it lets exceptions through).\n\n    '''\n    def __init__(self):\n        # Open a pair of null files\n        self.null_fds = [os.open(os.devnull, os.O_RDWR) for x in range(2)]\n        # Save the actual stdout (1) and stderr (2) file descriptors.\n        self.save_fds = [os.dup(1), os.dup(2)]\n\n    def __enter__(self):\n        # Assign the null pointers to stdout and stderr.\n        os.dup2(self.null_fds[0], 1)\n        os.dup2(self.null_fds[1], 2)\n\n    def __exit__(self, *_):\n        # Re-assign the real stdout/stderr back to (1) and (2)\n        os.dup2(self.save_fds[0], 1)\n        os.dup2(self.save_fds[1], 2)\n        # Close the null files\n        for fd in self.null_fds + self.save_fds:\n            os.close(fd)\n\n\ninit = time.time()\nwith suppress_stdout_stderr():\n    with Pool(cpu_count()) as pool:\n        forecast_prophet = pool.starmap(fit_and_predict, train.groupby('unique_id'))\nend = time.time()\nforecast_prophet = pd.concat(forecast_prophet).rename(columns={'yhat': 'prophet'})\ntime_prophet = end - init\ntime_prophet\n\n2022-08-19 23:07:24 prophet.models WARNING: Optimization terminated abnormally. Falling back to Newton.\n2022-08-19 23:07:25 prophet.models WARNING: Optimization terminated abnormally. Falling back to Newton.\n2022-08-19 23:07:41 prophet.models WARNING: Optimization terminated abnormally. Falling back to Newton.\n2022-08-19 23:07:42 prophet.models WARNING: Optimization terminated abnormally. Falling back to Newton.\n2022-08-19 23:08:00 prophet.models WARNING: Optimization terminated abnormally. Falling back to Newton.\n\n\n120.9244737625122\n\n\n\nforecast_prophet\n\n\n\n\n\n  \n    \n      \n      unique_id\n      ds\n      prophet\n    \n  \n  \n    \n      0\n      H1\n      701\n      631.867439\n    \n    \n      1\n      H1\n      702\n      561.001661\n    \n    \n      2\n      H1\n      703\n      499.299334\n    \n    \n      3\n      H1\n      704\n      456.132082\n    \n    \n      4\n      H1\n      705\n      431.884528\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      43\n      H112\n      744\n      5634.503804\n    \n    \n      44\n      H112\n      745\n      5622.643542\n    \n    \n      45\n      H112\n      746\n      5546.302705\n    \n    \n      46\n      H112\n      747\n      5457.777165\n    \n    \n      47\n      H112\n      748\n      5373.944098\n    \n  \n\n768 rows × 3 columns\n\n\n\n\ntest = test.merge(forecast_prophet, how='left', on=['unique_id', 'ds'])\n\n\nplot_grid(train, test)\n\n\n\n\n\n\nEvaluation\n\n\nTime\nSince AutoARIMA works with numba is useful to calculate the time for just one time series.\n\nfcst = StatsForecast(df=train.query('unique_id == \"H1\"'), \n                     models=models, freq='H', \n                     n_jobs=1)\n\n\ninit = time.time()\nforecasts = fcst.forecast(48)\nend = time.time()\n\ntime_nixtla_1 = end - init\ntime_nixtla_1\n\n11.437001705169678\n\n\n\ntimes = pd.DataFrame({'n_series': np.arange(1, 414 + 1)})\ntimes['pmdarima'] = time_pmdarima * times['n_series'] / n_series_pmdarima\ntimes['prophet'] = time_prophet * times['n_series'] / n_series\ntimes['AutoARIMA_nixtla'] = time_nixtla_1 + times['n_series'] * (time_nixtla - time_nixtla_1) / n_series\ntimes = times.set_index('n_series')\n\n\ntimes.tail(5)\n\n\n\n\n\n  \n    \n      \n      pmdarima\n      prophet\n      AutoARIMA_nixtla\n    \n    \n      n_series\n      \n      \n      \n    \n  \n  \n    \n      410\n      71736.927578\n      3098.689640\n      240.181212\n    \n    \n      411\n      71911.895694\n      3106.247420\n      240.739124\n    \n    \n      412\n      72086.863811\n      3113.805199\n      241.297037\n    \n    \n      413\n      72261.831927\n      3121.362979\n      241.854950\n    \n    \n      414\n      72436.800043\n      3128.920759\n      242.412863\n    \n  \n\n\n\n\n\nfig, axes = plt.subplots(1, 2, figsize = (24, 7))\n(times/3600).plot(ax=axes[0], linewidth=4)\nnp.log10(times).plot(ax=axes[1], linewidth=4)\naxes[0].set_title('Time across models [Hours]', fontsize=22)\naxes[1].set_title('Time across models [Log10 Scale]', fontsize=22)\naxes[0].set_ylabel('Time [Hours]', fontsize=20)\naxes[1].set_ylabel('Time Seconds [Log10 Scale]', fontsize=20)\nfig.suptitle('Time comparison using M4-Hourly data', fontsize=27)\nfor ax in axes:\n    ax.set_xlabel('Number of Time Series [N]', fontsize=20)\n    ax.legend(prop={'size': 20})\n    ax.grid()\n    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n        label.set_fontsize(20)\n\n\n\n\n\nfig.savefig('computational-efficiency.png', dpi=300)\n\n\n\nPerformance\n\npmdarima (only two time series)\n\nname_models = test.drop(['unique_id', 'ds', 'y_test'], 1).columns.tolist()\n\n\ntest_pmdarima = test.query('unique_id in [\"H1\", \"H10\"]')\neval_pmdarima = []\nfor model in name_models:\n    mae = np.mean(abs(test_pmdarima[model] - test_pmdarima['y_test']))\n    eval_pmdarima.append({'model': model, 'mae': mae})\npd.DataFrame(eval_pmdarima).sort_values('mae')\n\n\n\n\n\n  \n    \n      \n      model\n      mae\n    \n  \n  \n    \n      0\n      AutoARIMA\n      20.289669\n    \n    \n      1\n      pmdarima\n      26.461525\n    \n    \n      2\n      prophet\n      43.155861\n    \n  \n\n\n\n\n\n\nProphet\n\neval_prophet = []\nfor model in name_models:\n    if 'pmdarima' in model:\n        continue\n    mae = np.mean(abs(test[model] - test['y_test']))\n    eval_prophet.append({'model': model, 'mae': mae})\npd.DataFrame(eval_prophet).sort_values('mae')\n\n\n\n\n\n  \n    \n      \n      model\n      mae\n    \n  \n  \n    \n      0\n      AutoARIMA\n      680.202970\n    \n    \n      1\n      prophet\n      1066.049049\n    \n  \n\n\n\n\nFor a complete comparison check the complete experiment."
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": " Core ",
    "section": "",
    "text": "source\n\n\n\n StatsForecast (models:List[Any], freq:str, n_jobs:int=1,\n                ray_address:Optional[str]=None,\n                df:Optional[pandas.core.frame.DataFrame]=None,\n                sort_df:bool=True, fallback_model:Any=None)\n\ncore.StatsForecast. Source code.\nThe core.StatsForecast class allows you to efficiently fit multiple StatsForecast models for large sets of time series. It operates with pandas DataFrame df that identifies series and datestamps with the unique_id and ds columns. The y column denotes the target time series variable.\nThe class has memory-efficient StatsForecast.forecast method that avoids storing partial model outputs. While the StatsForecast.fit and StatsForecast.predict methods with Scikit-learn interface store the fitted models.\nParameters: df: pandas.DataFrame, with columns [unique_id, ds, y] and exogenous. models: List[typing.Any], list of instantiated objects models.StatsForecast. freq: str, frequency of the data, panda’s available frequencies. n_jobs: int, number of jobs used in the parallel processing, use -1 for all cores. sort_df: bool, if True, sort df by [unique_id,ds]. fallback_model: Any, Model to be used if a model fails. Only works with the forecast method.\nNotes: The core.StatsForecast class offers parallelization utilities with Dask, Spark and Ray back-ends. See distributed computing example here.\n\n# StatsForecast's class usage example\n\n#from statsforecast.core import StatsForecast\nfrom statsforecast.utils import generate_series\nfrom statsforecast.models import ( \n    ADIDA,\n    AutoARIMA,\n    CrostonClassic,\n    CrostonOptimized,\n    CrostonSBA,\n    ETS,\n    HistoricAverage,\n    IMAPA,\n    Naive,\n    RandomWalkWithDrift,\n    SeasonalExponentialSmoothing,\n    SeasonalNaive,\n    SeasonalWindowAverage,\n    SimpleExponentialSmoothing,\n    TSB,\n    WindowAverage,\n)\n\n# Generate synthetic panel DataFrame for example\npanel_df = generate_series(n_series=2, equal_ends=False)\npanel_df.groupby('unique_id').tail(4)\n\n\n\n\n\n  \n    \n      \n      ds\n      y\n    \n    \n      unique_id\n      \n      \n    \n  \n  \n    \n      0\n      2000-08-06\n      1.415524\n    \n    \n      0\n      2000-08-07\n      2.314491\n    \n    \n      0\n      2000-08-08\n      3.436325\n    \n    \n      0\n      2000-08-09\n      4.136771\n    \n    \n      1\n      2000-04-03\n      0.210270\n    \n    \n      1\n      2000-04-04\n      1.278684\n    \n    \n      1\n      2000-04-05\n      2.430276\n    \n    \n      1\n      2000-04-06\n      3.363522\n    \n  \n\n\n\n\n\n# Declare list of instantiated StatsForecast estimators to be fitted\n# You can try other estimator's hyperparameters\n# You can try other methods from the `models.StatsForecast` collection\n# Check them here: https://nixtla.github.io/statsforecast/models.html\nmodels=[AutoARIMA(), Naive()] \n\n# Instantiate StatsForecast class\nfcst = StatsForecast(df=panel_df,\n                     models=models,\n                     freq='D', n_jobs=1)\n\n# Efficiently predict\nfcsts_df = fcst.forecast(h=4, fitted=True)\nfcsts_df.groupby('unique_id').tail(4)\n\n\n\n\n\nsource\n\n\n\n StatsForecast.forecast (h:int,\n                         df:Optional[pandas.core.frame.DataFrame]=None,\n                         X_df:Optional[pandas.core.frame.DataFrame]=None,\n                         level:Optional[List[int]]=None,\n                         fitted:bool=False, sort_df:bool=True)\n\nMemory Efficient core.StatsForecast predictions.\nThis method avoids memory burden due from object storage. It is analogous to Scikit-Learn fit_predict without storing information. It requires the forecast horizon h in advance.\nParameters: h: int, forecast horizon. df: pandas.DataFrame, with columns [unique_id, ds, y] and exogenous. X_df: pandas.DataFrame, with [unique_id, ds] columns and df’s future exogenous. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions. sort_df: bool, if True, sort df by [unique_id,ds].\nReturns: fcsts_df: pandas.DataFrame, with models columns for point predictions and probabilistic predictions for all fitted models.\n\n# StatsForecast.forecast method usage example\n\n#from statsforecast.core import StatsForecast\nfrom statsforecast.utils import AirPassengersDF as panel_df\nfrom statsforecast.models import AutoARIMA, Naive\n\n# Instantiate StatsForecast class\nfcst = StatsForecast(df=panel_df,\n                     models=[AutoARIMA(), Naive()],\n                     freq='D', n_jobs=1)\n\n# Efficiently predict without storing memory\nfcsts_df = fcst.forecast(h=4, fitted=True)\nfcsts_df.groupby('unique_id').tail(4)\n\n\n\n\n\n  \n    \n      \n      ds\n      AutoARIMA\n      Naive\n    \n    \n      unique_id\n      \n      \n      \n    \n  \n  \n    \n      1.0\n      1961-01-01\n      476.006500\n      432.0\n    \n    \n      1.0\n      1961-01-02\n      482.846222\n      432.0\n    \n    \n      1.0\n      1961-01-03\n      512.423523\n      432.0\n    \n    \n      1.0\n      1961-01-04\n      502.038269\n      432.0\n    \n  \n\n\n\n\n\nsource\n\n\n\n\n StatsForecast.forecast_fitted_values ()\n\nAccess core.StatsForecast insample predictions.\nAfter executing StatsForecast.forecast, you can access the insample prediction values for each model. To get them, you need to pass fitted=True to the StatsForecast.forecast method and then use the StatsForecast.forecast_fitted_values method.\nParameters: Check StatsForecast.forecast parameters, use fitted=True.\nReturns: fcsts_df: pandas.DataFrame, with insample models columns for point predictions and probabilistic predictions for all fitted models.\n\n# StatsForecast.forecast_fitted_values method usage example\n\n#from statsforecast.core import StatsForecast\nfrom statsforecast.utils import AirPassengersDF as panel_df\nfrom statsforecast.models import Naive\n\n# Instantiate StatsForecast class\nfcst = StatsForecast(df=panel_df,\n                     models=[AutoARIMA()],\n                     freq='D', n_jobs=1)\n\n# Access insample predictions\nfcsts_df = fcst.forecast(h=12, fitted=True, level=(90, 10))\ninsample_fcsts_df = fcst.forecast_fitted_values()\ninsample_fcsts_df.tail(4)\n\n\n\n\n\n  \n    \n      \n      ds\n      y\n      AutoARIMA\n      AutoARIMA-lo-90\n      AutoARIMA-lo-10\n      AutoARIMA-hi-10\n      AutoARIMA-hi-90\n    \n    \n      unique_id\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1.0\n      1960-09-30\n      508.0\n      572.654175\n      525.092163\n      569.020630\n      576.287781\n      620.216187\n    \n    \n      1.0\n      1960-10-31\n      461.0\n      451.528259\n      403.966248\n      447.894684\n      455.161835\n      499.090271\n    \n    \n      1.0\n      1960-11-30\n      390.0\n      437.915375\n      390.353394\n      434.281799\n      441.548981\n      485.477386\n    \n    \n      1.0\n      1960-12-31\n      432.0\n      369.718781\n      322.156769\n      366.085205\n      373.352356\n      417.280792\n    \n  \n\n\n\n\n\nsource\n\n\n\n\n StatsForecast.cross_validation (h:int,\n                                 df:Optional[pandas.core.frame.DataFrame]=\n                                 None, n_windows:int=1, step_size:int=1,\n                                 test_size:Optional[int]=None,\n                                 input_size:Optional[int]=None,\n                                 level:Optional[List[int]]=None,\n                                 fitted:bool=False, sort_df:bool=True)\n\nTemporal Cross-Validation with core.StatsForecast.\ncore.StatsForecast’s cross-validation efficiently fits a list of StatsForecast models through multiple training windows, in either chained or rolled manner.\nStatsForecast.models’ speed allows to overcome this evaluation technique high computational costs. Temporal cross-validation provides better model’s generalization measurements by increasing the test’s length and diversity.\nParameters: h: int, forecast horizon. df: pandas.DataFrame, with columns [unique_id, ds, y] and exogenous. n_windows: int, number of windows used for cross validation. step_size: int = 1, step size between each window. test_size: Optional[int] = None, length of test size. If passed, set n_windows=None. input_size: Optional[int] = None, input size for each window, if not none rolled windows. level: float list 0-100, confidence levels for prediction intervals. fitted: bool, wether or not returns insample predictions. sort_df: bool, if True, sort df by unique_id and ds.\nReturns: fcsts_df: pandas.DataFrame, with insample models columns for point predictions and probabilistic predictions for all fitted models.\n\n# StatsForecast.crossvalidation method usage example\n\n#from statsforecast.core import StatsForecast\nfrom statsforecast.utils import AirPassengersDF as panel_df\nfrom statsforecast.models import Naive\n\n# Instantiate StatsForecast class\nfcst = StatsForecast(df=panel_df,\n                     models=[Naive()],\n                     freq='D', n_jobs=1)\n\n# Access insample predictions\nrolled_fcsts_df = fcst.cross_validation(14, n_windows=2)\nrolled_fcsts_df.head(4)\n\n\n\n\n\n  \n    \n      \n      ds\n      cutoff\n      y\n      Naive\n    \n    \n      unique_id\n      \n      \n      \n      \n    \n  \n  \n    \n      1.0\n      1960-12-17\n      1960-12-16\n      407.0\n      463.0\n    \n    \n      1.0\n      1960-12-18\n      1960-12-16\n      362.0\n      463.0\n    \n    \n      1.0\n      1960-12-19\n      1960-12-16\n      405.0\n      463.0\n    \n    \n      1.0\n      1960-12-20\n      1960-12-16\n      417.0\n      463.0\n    \n  \n\n\n\n\n\nsource\n\n\n\n\n StatsForecast.cross_validation_fitted_values ()\n\nAccess core.StatsForecast insample cross validated predictions.\nAfter executing StatsForecast.cross_validation, you can access the insample prediction values for each model and window. To get them, you need to pass fitted=True to the StatsForecast.cross_validation method and then use the StatsForecast.cross_validation_fitted_values method.\nParameters: Check StatsForecast.cross_validation parameters, use fitted=True.\nReturns: fcsts_df: pandas.DataFrame, with insample models columns for point predictions and probabilistic predictions for all fitted models.\n\n# StatsForecast.cross_validation_fitted_values method usage example\n\n#from statsforecast.core import StatsForecast\nfrom statsforecast.utils import AirPassengersDF as panel_df\nfrom statsforecast.models import Naive\n\n# Instantiate StatsForecast class\nfcst = StatsForecast(df=panel_df,\n                     models=[Naive()],\n                     freq='D', n_jobs=1)\n\n# Access insample predictions\nrolled_fcsts_df = fcst.cross_validation(h=12, n_windows=2, fitted=True)\ninsample_rolled_fcsts_df = fcst.cross_validation_fitted_values()\ninsample_rolled_fcsts_df.tail(4)\n\n\n\n\n\n  \n    \n      \n      ds\n      cutoff\n      y\n      Naive\n    \n    \n      unique_id\n      \n      \n      \n      \n    \n  \n  \n    \n      1.0\n      1959-09-30\n      1959-12-31\n      463.0\n      559.0\n    \n    \n      1.0\n      1959-10-31\n      1959-12-31\n      407.0\n      463.0\n    \n    \n      1.0\n      1959-11-30\n      1959-12-31\n      362.0\n      407.0\n    \n    \n      1.0\n      1959-12-31\n      1959-12-31\n      405.0\n      362.0\n    \n  \n\n\n\n\n\n\n\n\n\nsource\n\n\n\n StatsForecast.fit (df:Optional[pandas.core.frame.DataFrame]=None,\n                    sort_df:bool=True)\n\nFit the core.StatsForecast.\nFit models to a large set of time series from DataFrame df. and store fitted models for later inspection.\nParameters: df: pandas.DataFrame, with columns [unique_id, ds, y] and exogenous. sort_df: bool, if True, sort df by [unique_id,ds].\nReturns: self: Returns with stored StatsForecast fitted models.\n\nsource\n\n\n\n\n StatsForecast.predict (h:int,\n                        X_df:Optional[pandas.core.frame.DataFrame]=None,\n                        level:Optional[List[int]]=None)\n\nPredict with core.StatsForecast.\nUse stored fitted models to predict large set of time series from DataFrame df.\nParameters: h: int, forecast horizon. X_df: pandas.DataFrame, with [unique_id, ds] columns and df’s future exogenous. level: float list 0-100, confidence levels for prediction intervals.\nReturns: fcsts_df: pandas.DataFrame, with models columns for point predictions and probabilistic predictions for all fitted models.\n\nsource\n\n\n\n\n StatsForecast.fit_predict (h:int,\n                            df:Optional[pandas.core.frame.DataFrame]=None,\n                            X_df:Optional[pandas.core.frame.DataFrame]=Non\n                            e, level:Optional[List[int]]=None,\n                            sort_df:bool=True)\n\nFit and Predict with core.StatsForecast.\nThis method avoids memory burden due from object storage. It is analogous to Scikit-Learn fit_predict without storing information. It requires the forecast horizon h in advance.\nIn contrast to StatsForecast.forecast this method stores partial models outputs.\nParameters: h: int, forecast horizon. df: pandas.DataFrame, with columns [unique_id, ds, y] and exogenous. X_df: pandas.DataFrame, with [unique_id, ds] columns and df’s future exogenous. level: float list 0-100, confidence levels for prediction intervals. sort_df: bool, if True, sort df by [unique_id,ds].\nReturns: fcsts_df: pandas.DataFrame, with models columns for point predictions and probabilistic predictions for all fitted models."
  },
  {
    "objectID": "core.html#integer-datestamp",
    "href": "core.html#integer-datestamp",
    "title": " Core ",
    "section": "Integer datestamp",
    "text": "Integer datestamp\nThe StatsForecast class can also receive integers as datestamp, the following example shows how to do it.\n\nfrom statsforecast.core import StatsForecast\nfrom statsforecast.utils import AirPassengers as ap\nfrom statsforecast.models import HistoricAverage\n\n\nint_ds_df = pd.DataFrame({'ds': np.arange(1, len(ap) + 1), 'y': ap})\nint_ds_df.insert(0, 'unique_id', 'AirPassengers')\nint_ds_df.set_index('unique_id', inplace=True)\nint_ds_df.head()\n\n\nint_ds_df.tail()\n\n\nfcst = StatsForecast(df=int_ds_df, models=[HistoricAverage()], freq='D')\nhorizon = 7\nforecast = fcst.forecast(horizon)\nforecast.head()\n\n\nlast_date = int_ds_df['ds'].max()\ntest_eq(forecast['ds'].values, np.arange(last_date + 1, last_date + 1 + horizon))\n\n\nint_ds_cv = fcst.cross_validation(h=7, test_size=8, n_windows=None)\nint_ds_cv"
  },
  {
    "objectID": "core.html#external-regressors",
    "href": "core.html#external-regressors",
    "title": " Core ",
    "section": "External regressors",
    "text": "External regressors\nEvery column after y is considered an external regressor and will be passed to the models that allow them. If you use them you must supply the future values to the StatsForecast.forecast method.\n\nclass LinearRegression:\n    \n    def __init__(self):\n        pass\n    \n    def fit(self, y, X):\n        self.coefs_, *_ = np.linalg.lstsq(X, y, rcond=None)\n        return self\n    \n    def predict(self, h, X):\n        mean = X @ coefs\n        return mean\n    \n    def __repr__(self):\n        return 'LinearRegression()'\n    \n    def forecast(self, y, h, X=None, X_future=None, fitted=False):\n        coefs, *_ = np.linalg.lstsq(X, y, rcond=None)\n        return {'mean': X_future @ coefs}\n    \n    def new(self):\n        b = type(self).__new__(type(self))\n        b.__dict__.update(self.__dict__)\n        return b\n\n\nseries_xreg = series = generate_series(10_000, equal_ends=True)\nseries_xreg['intercept'] = 1\nseries_xreg['dayofweek'] = series_xreg['ds'].dt.dayofweek\nseries_xreg = pd.get_dummies(series_xreg, columns=['dayofweek'], drop_first=True)\nseries_xreg\n\n\ndates = sorted(series_xreg['ds'].unique())\nvalid_start = dates[-14]\ntrain_mask = series_xreg['ds'] < valid_start\nseries_train = series_xreg[train_mask]\nseries_valid = series_xreg[~train_mask]\nX_valid = series_valid.drop(columns=['y'])\nfcst = StatsForecast(\n    df=series_train,\n    models=[LinearRegression()],\n    freq='D',\n)\nxreg_res = fcst.forecast(14, X_df=X_valid)\nxreg_res['y'] = series_valid['y'].values\n\n\nxreg_res.groupby('ds').mean().plot()\n\n\nxreg_res_cv = fcst.cross_validation(h=3, test_size=5, n_windows=None)"
  },
  {
    "objectID": "core.html#confidence-intervals",
    "href": "core.html#confidence-intervals",
    "title": " Core ",
    "section": "Confidence intervals",
    "text": "Confidence intervals\nYou can pass the argument level to the StatsForecast.forecast method to calculate confidence intervals. Not all models can calculate them at the moment, so we will only obtain the intervals of those models that have it implemented.\n\nap_df = pd.DataFrame({'ds': np.arange(ap.size), 'y': ap}, index=pd.Index([0] * ap.size, name='unique_id'))\nfcst = StatsForecast(\n    df=ap_df,\n    models=[\n        SeasonalNaive(season_length=12), \n        AutoARIMA(season_length=12)\n    ],\n    freq='M',\n    n_jobs=1\n)\nap_ci = fcst.forecast(12, level=(80, 95))\nap_ci.set_index('ds').plot(marker='.', figsize=(10, 6))\n\n\n#hide\ndef test_conf_intervals(n_jobs=1):\n    ap_df = pd.DataFrame({'ds': np.arange(ap.size), 'y': ap}, index=pd.Index([0] * ap.size, name='unique_id'))\n    fcst = StatsForecast(\n        df=ap_df,\n        models=[\n            SeasonalNaive(season_length=12), \n            AutoARIMA(season_length=12)\n        ],\n        freq='M',\n        n_jobs=n_jobs\n    )\n    ap_ci = fcst.forecast(12, level=(80, 95))\n    ap_ci.set_index('ds').plot(marker='.', figsize=(10, 6))\ntest_conf_intervals(n_jobs=1)"
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "",
    "text": "By Fugue and Nixtla. Originally posted on TDS.\nTime-series modeling, analysis, and prediction of trends and seasonalities for data collected over time is a rapidly growing category of software applications.\nBusinesses, from electricity and economics to healthcare analytics, collect time-series data daily to predict patterns and build better data-driven product experiences. For example, temperature and humidity prediction is used in manufacturing to prevent defects, streaming metrics predictions help identify music’s popular artists, and sales forecasting for thousands of SKUs across different locations in the supply chain is used to optimize inventory costs. As data generation increases, the forecasting necessities have evolved from modeling a few time series to predicting millions."
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html#motivation",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html#motivation",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "Motivation",
    "text": "Motivation\nNixtla is an open-source project focused on state-of-the-art time series forecasting. They have a couple of libraries such as StatsForecast for statistical models, NeuralForecast for deep learning, and HierarchicalForecast for forecast aggregations across different levels of hierarchies. These are production-ready time series libraries focused on different modeling techniques.\nThis article looks at StatsForecast, a lightning-fast forecasting library with statistical and econometrics models. The AutoARIMA model of Nixtla is 20x faster than pmdarima, and the ETS (error, trend, seasonal) models performed 4x faster than statsmodels and are more robust. The benchmarks and code to reproduce can be found here. A huge part of the performance increase is due to using a JIT compiler called numba to achieve high speeds.\nThe faster iteration time means that data scientists can run more experiments and converge to more accurate models faster. It also means that running benchmarks at scale becomes easier.\nIn this article, we are interested in the scalability of the StatsForecast library in fitting models over Spark or Dask using the Fugue library. This combination will allow us to train a huge number of models distributedly over a temporary cluster quickly."
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html#experiment-setup",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html#experiment-setup",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "Experiment Setup",
    "text": "Experiment Setup\nWhen dealing with large time series data, users normally have to deal with thousands of logically independent time series (think of telemetry of different users or different product sales). In this case, we can train one big model over all of the series, or we can create one model for each series. Both are valid approaches since the bigger model will pick up trends across the population, while training thousands of models may fit individual series data better.\n\n\n\n\n\n\nNote\n\n\n\nNote: to pick up both the micro and macro trends of the time series population in one model, check the Nixtla HierarchicalForecast library, but this is also more computationally expensive and trickier to scale.\n\n\nThis article will deal with the scenario where we train a couple of models (AutoARIMA or ETS) per univariate time series. For this setup, we group the full data by time series, and then train each model for each group. The image below illustrates this. The distributed DataFrame can either be a Spark or Dask DataFrame.\n\n\n\nAutoARIMA per partition\n\n\nNixtla previously released benchmarks with Anyscale on distributing this model training on Ray. The setup and results can be found in this blog. The results are also shown below. It took 2000 cpus to run one million AutoARIMA models in 35 minutes. We’ll compare this against running on Spark.\n\n\n\nStatsForecast on Ray results"
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html#statsforecast-code",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html#statsforecast-code",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "StatsForecast code",
    "text": "StatsForecast code\nFirst, we’ll look at the StatsForecast code used to run the AutoARIMA distributedly on Ray. This is a simplified version to run the scenario with a one million time series. It is also updated for the recent StatsForecast v1.0.0 release, so it may look a bit different from the code in the previous benchmarks.\nfrom time import time\n\nimport pandas as pd\nfrom statsforecast.utils import generate_series\nfrom statsforecast.models import AutoARIMA\nfrom statsforecast.core import StatsForecast\n\nseries = generate_series(n_series=1000000, seed=1)\n\nmodel = StatsForecast(df=series,\n                      models=[AutoARIMA()], \n                      freq='D', \n                      n_jobs=-1,\n              ray_address=ray_address)\n\ninit = time()\nforecasts = model.forecast(7)\nprint(f'n_series: 1000000 total time: {(time() - init) / 60}')\nThe interface of StatsForecast is very minimal. It is already designed to perform the AutoARIMA on each group of data. Just supplying the ray_address will make this code snippet run distributedly. Without it, n_jobswill indicate the number of parallel processes for forecasting. model.forecast() will do the fit and predict in one step, and the input to this method in the time horizon to forecast."
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html#using-fugue-to-run-on-spark-and-dask",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html#using-fugue-to-run-on-spark-and-dask",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "Using Fugue to run on Spark and Dask",
    "text": "Using Fugue to run on Spark and Dask\nFugue is an abstraction layer that ports Python, Pandas, and SQL code to Spark and Dask. The most minimal interface is the transform() function. This function takes in a function and DataFrame, and brings it to Spark or Dask. We can use the transform() function to bring StatsForecast execution to Spark.\nThere are two parts to the code below. First, we have the forecast logic defined in the forecast_series function. Some parameters are hardcoded for simplicity. The most important one is that n_jobs=1. This is because Spark or Dask will already serve as the parallelization layer, and having two stages of parallelism can cause resource deadlocks.\nfrom fugue import transform\n\ndef forecast_series(df: pd.DataFrame, models) -> pd.DataFrame:\n    tdf = df.set_index(\"unique_id\")\n    model = StatsForecast(df=tdf, models=models, freq='D', n_jobs=1)\n    return model.forecast(7).reset_index()\n\ntransform(series.reset_index(),\n          forecast_series,\n          params=dict(models=[AutoARIMA()]),\n          schema=\"unique_id:int, ds:date, AutoARIMA:float\",\n          partition={\"by\": \"unique_id\"},\n          engine=\"spark\"\n          ).show()\nSecond, the transform() function is used to apply the forecast_series() function on Spark. The first two arguments are the DataFrame and function to be applied. Output schema is a requirement for Spark, so we need to pass it in, and the partition argument will take care of splitting the time series modelling by unique_id.\nThis code already works and returns a Spark DataFrame output."
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html#nixtlas-fuguebackend",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html#nixtlas-fuguebackend",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "Nixtla’s FugueBackend",
    "text": "Nixtla’s FugueBackend\nThe transform() above is a general look at what Fugue can do. In practice, the Fugue and Nixtla teams collaborated to add a more native FugueBackend to the StatsForecast library. Along with it is a utility forecast() function to simplify the forecasting interface. Below is an end-to-end example of running StatsForecast on one million time series.\nfrom statsforecast.distributed.utils import forecast\nfrom statsforecast.distributed.fugue import FugueBackend\nfrom statsforecast.models import AutoARIMA\nfrom statsforecast.core import StatsForecast\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\nbackend = FugueBackend(spark, {\"fugue.spark.use_pandas_udf\":True})\n\nforecast(spark.read.parquet(\"/tmp/1m.parquet\"), \n         [AutoARIMA()], \n         freq=\"D\", \n         h=7, \n         parallel=backend).toPandas()\nWe just need to create the FugueBackend, which takes in a SparkSession and passes it to forecast(). This function can take either a DataFrame or file path to the data. If a file path is provided, it will be loaded with the parallel backend. In this example above, we replaced the file each time we ran the experiment to generate benchmarks.\n\n\n\n\n\n\nDanger\n\n\n\nIt’s also important to note that we can test locally before running the forecast() on full data. All we have to do is not supply anything for the parallel argument; everything will run on Pandas sequentially."
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html#benchmark-results",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html#benchmark-results",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "Benchmark Results",
    "text": "Benchmark Results\nThe benchmark results can be seen below. As of the time of this writing, Dask and Ray made recent releases, so only the Spark metrics are up to date. We will make a follow-up article after running these experiments with the updates.\n\n\n\nSpark and Dask benchmarks for StatsForecast at scale\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: The attempt was to use 2000 cpus but we were limited by available compute instances on AWS.\n\n\nThe important part here is that AutoARIMA trained one million time series models in less than 15 minutes. The cluster configuration is attached in the appendix. With very few lines of code, we were able to orchestrate the training of these time series models distributedly."
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html#conclusion",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html#conclusion",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "Conclusion",
    "text": "Conclusion\nTraining thousands of time series models distributedly normally takes a lot of coding with Spark and Dask, but we were able to run these experiments with very few lines of code. Nixtla’s StatsForecast offers the ability to quickly utilize all of the compute resources available to find the best model for each time series. All users need to do is supply a relevant parallel backend (Ray or Fugue) to run on a cluster.\nOn the scale of one million timeseries, our total training time took 12 minutes for AutoARIMA. This is the equivalent of close to 400 cpu-hours that we ran immediately, allowing data scientists to quickly iterate at scale without having to write the explicit code for parallelization. Because we used an ephemeral cluster, the cost is effectively the same as running this sequentially on an EC2 instance (parallelized over all cores)."
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html#resources",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html#resources",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "Resources",
    "text": "Resources\n\nNixtla StatsForecast repo\nStatsForecast docs\nFugue repo\nFugue tutorials\n\nTo chat with us:\n\nFugue Slack\nNixtla Slack"
  },
  {
    "objectID": "blog/posts/2022-10-05-distributed-fugue/index.html#appendix",
    "href": "blog/posts/2022-10-05-distributed-fugue/index.html#appendix",
    "title": "Scalable Time Series Modeling with open-source projects",
    "section": "Appendix",
    "text": "Appendix\nFor anyone. interested in the cluster configuration, it can be seen below. This will spin up a Databricks cluster. The important thing is the node_type_id that has the machines used.\n{\n    \"num_workers\": 20,\n    \"cluster_name\": \"fugue-nixtla-2\",\n    \"spark_version\": \"10.4.x-scala2.12\",\n    \"spark_conf\": {\n        \"spark.speculation\": \"true\",\n        \"spark.sql.shuffle.partitions\": \"8000\",\n        \"spark.sql.adaptive.enabled\": \"false\",\n        \"spark.task.cpus\": \"1\"\n    },\n    \"aws_attributes\": {\n        \"first_on_demand\": 1,\n        \"availability\": \"SPOT_WITH_FALLBACK\",\n        \"zone_id\": \"us-west-2c\",\n        \"spot_bid_price_percent\": 100,\n        \"ebs_volume_type\": \"GENERAL_PURPOSE_SSD\",\n        \"ebs_volume_count\": 1,\n        \"ebs_volume_size\": 32\n    },\n    \"node_type_id\": \"m5.24xlarge\",\n    \"driver_node_type_id\": \"m5.2xlarge\",\n    \"ssh_public_keys\": [],\n    \"custom_tags\": {},\n    \"spark_env_vars\": {\n        \"MKL_NUM_THREADS\": \"1\",\n        \"OPENBLAS_NUM_THREADS\": \"1\",\n        \"VECLIB_MAXIMUM_THREADS\": \"1\",\n        \"OMP_NUM_THREADS\": \"1\",\n        \"NUMEXPR_NUM_THREADS\": \"1\"\n    },\n    \"autotermination_minutes\": 20,\n    \"enable_elastic_disk\": false,\n    \"cluster_source\": \"UI\",\n    \"init_scripts\": [],\n    \"runtime_engine\": \"STANDARD\",\n    \"cluster_id\": \"0728-004950-oefym0ss\"\n}"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "StatsForecast Blog",
    "section": "",
    "text": "How to Forecast 1M Time Series in 15 Minutes with Spark, Fugue and Nixtla’s Statsforecast.\n\n\n\n\n\n\nOct 5, 2022\n\n\nFugue, Nixtla\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical ⚡️ Forecast",
    "section": "",
    "text": "You can install the released version of StatsForecast from the Python package index with:\npip install statsforecast\n(Installing inside a python virtualenvironment or a conda environment is recommended.)\n\n\n\nAlso you can install the released version of StatsForecast from conda with:\nconda install -c conda-forge statsforecast\n(Installing inside a python virtualenvironment or a conda environment is recommended.)\n\n\n\nIf you want to make some modifications to the code and see the effects in real time (without reinstalling), follow the steps below:\ngit clone https://github.com/Nixtla/statsforecast.git\ncd statsforecast\npip install -e .\nTo get started just follow this guide."
  },
  {
    "objectID": "index.html#new",
    "href": "index.html#new",
    "title": "Statistical ⚡️ Forecast",
    "section": "🎉 New!",
    "text": "🎉 New!\n\n ETS Example: 4x faster than StatsModels with improved accuracy and robustness.\n Complete pipeline and comparison: 20x faster than pmdarima and 500x faster than Prophet."
  },
  {
    "objectID": "index.html#highlights",
    "href": "index.html#highlights",
    "title": "Statistical ⚡️ Forecast",
    "section": "🔥 Highlights",
    "text": "🔥 Highlights\n\nFastest and most accurate AutoARIMA in Python and R.\nFastest and most accurate ETS in Python and R.\nNew!: Replace FB-Prophet in two lines of code and gain speed and accuracy. Check the experiments here.\nNew!: Distributed computation in clusters with ray. (Forecast 1M series in 30min)\nNew!: Good Ol’ sklearn syntax with AutoARIMA (AutoARIMA().fit(y).predict(h=7)."
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "Statistical ⚡️ Forecast",
    "section": "🎊 Features",
    "text": "🎊 Features\n\nInclusion of exogenous variables and prediction intervals for ARIMA.\n20x faster than pmdarima.\n1.5x faster than R.\n500x faster than Prophet.\n4x faster than statsmodels.\nCompiled to high performance machine code through numba.\n1,000,000 series in 30 min with ray.\nOut of the box implementation of ADIDA, HistoricAverage, CrostonClassic, CrostonSBA, CrostonOptimized, SeasonalWindowAverage, SeasonalNaive, IMAPA Naive, RandomWalkWithDrift, WindowAverage, SeasonalExponentialSmoothing, TSB, AutoARIMA and ETS.\n\nMissing something? Please open an issue or write us in"
  },
  {
    "objectID": "index.html#why",
    "href": "index.html#why",
    "title": "Statistical ⚡️ Forecast",
    "section": "📖 Why?",
    "text": "📖 Why?\nCurrent Python alternatives for statistical models are slow, inaccurate and don’t scale well. So we created a library that can be used to forecast in production environments or as benchmarks. StatsForecast includes an extensive battery of models that can efficiently fit millions of time series."
  },
  {
    "objectID": "index.html#accuracy-speed",
    "href": "index.html#accuracy-speed",
    "title": "Statistical ⚡️ Forecast",
    "section": "🔬 Accuracy & ⏲ Speed",
    "text": "🔬 Accuracy & ⏲ Speed\n\nARIMA\nThe AutoARIMA model implemented in StatsForecast is 20x faster than pmdarima and 1.5x faster than R while improving accuracy. You can see the exact comparison and reproduce the results here.\n\n\nETS\nStatsForecast’s ETS is 4x faster than StatsModels’ and 1.6x faster than R’s, with improved accuracy and robustness. You can see the exact comparison and reproduce the resultshere\n\n\nBenchmarks at Scale\nWith StatsForecast you can fit 9 benchmark models on 1,000,000 series in under 5 min. Reproduce the results here."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Statistical ⚡️ Forecast",
    "section": "🧬 Getting Started",
    "text": "🧬 Getting Started\nYou can run this notebooks to get you started.\n\nExample of different AutoARIMA models on M4 data \n\nIn this notebook we present Nixtla’s AutoARIMA. The AutoARIMA model is widely used to forecast time series in production and as a benchmark. However, the alternative python implementation (pmdarima) is so slow that prevents data scientists from quickly iterating and deploying AutoARIMA in production for a large number of time series.\n\nShorter Example of fitting and AutoARIMA and an ETS model. \nBenchmarking 9 models on millions of series."
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "Statistical ⚡️ Forecast",
    "section": "🔨 How to contribute",
    "text": "🔨 How to contribute\nSee CONTRIBUTING.md."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Statistical ⚡️ Forecast",
    "section": "📃 References",
    "text": "📃 References\n\nThe AutoARIMA model is based (translated) from the R implementation included in the forecast package developed by Rob Hyndman.\nThe ETS model is based (translated) from the R implementation included in the forecast package developed by Rob Hyndman."
  },
  {
    "objectID": "arima.html",
    "href": "arima.html",
    "title": "ARIMA",
    "section": "",
    "text": "source\n\npredict_arima\n\n predict_arima (model, n_ahead, newxreg=None, se_fit=True)\n\n\nmyarima(ap, order=(2, 1, 1), seasonal={'order': (0, 1, 0), 'period': 12}, \n        constant=False, ic='aicc', method='CSS-ML')['aic']\n\n\nsource\n\n\narima_string\n\n arima_string (model, padding=False)\n\n\nsource\n\n\nforecast_arima\n\n forecast_arima (model, h=None, level=None, fan=False, xreg=None,\n                 blambda=None, bootstrap=False, npaths=5000, biasadj=None)\n\n\nsource\n\n\nfitted_arima\n\n fitted_arima (model, h=1)\n\nReturns h-step forecasts for the data used in fitting the model.\n\nsource\n\n\nauto_arima_f\n\n auto_arima_f (x, d=None, D=None, max_p=5, max_q=5, max_P=2, max_Q=2,\n               max_order=5, max_d=2, max_D=1, start_p=2, start_q=2,\n               start_P=1, start_Q=1, stationary=False, seasonal=True,\n               ic='aicc', stepwise=True, nmodels=94, trace=False,\n               approximation=None, method=None, truncate=None, xreg=None,\n               test='kpss', test_kwargs=None, seasonal_test='seas',\n               seasonal_test_kwargs=None, allowdrift=True, allowmean=True,\n               blambda=None, biasadj=False, parallel=False, num_cores=2,\n               period=1)\n\n\nsource\n\n\nprint_statsforecast_ARIMA\n\n print_statsforecast_ARIMA (model, digits=3, se=True)\n\n\nsource\n\n\nARIMASummary\n\n ARIMASummary (model)\n\nARIMA Summary.\n\nsource\n\n\nAutoARIMA\n\n AutoARIMA (d:Optional[int]=None, D:Optional[int]=None, max_p:int=5,\n            max_q:int=5, max_P:int=2, max_Q:int=2, max_order:int=5,\n            max_d:int=2, max_D:int=1, start_p:int=2, start_q:int=2,\n            start_P:int=1, start_Q:int=1, stationary:bool=False,\n            seasonal:bool=True, ic:str='aicc', stepwise:bool=True,\n            nmodels:int=94, trace:bool=False,\n            approximation:Optional[bool]=None, method:Optional[str]=None,\n            truncate:Optional[bool]=None, test:str='kpss',\n            test_kwargs:Optional[str]=None, seasonal_test:str='seas',\n            seasonal_test_kwargs:Optional[Dict]=None,\n            allowdrift:bool=True, allowmean:bool=True,\n            blambda:Optional[float]=None, biasadj:bool=False,\n            parallel:bool=False, num_cores:int=2, period:int=1)\n\nAn AutoARIMA estimator.\nReturns best ARIMA model according to either AIC, AICc or BIC value. The function conducts a search over possible model within the order constraints provided."
  }
]